[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 412: Bayesian Statistics",
    "section": "",
    "text": "Welcome to the website for Middlebury College’s Fall 2025 STAT 412. On this website you will find the course syllabus, schedule, and assignments. The website is frequently updated throughout the semester, so please make a habit of refreshing the page."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#announcements",
    "href": "index.html#announcements",
    "title": "STAT 412: Bayesian Statistics",
    "section": "Announcements",
    "text": "Announcements\n\nModified office hours Monday 11/10: 2:30-3:30pm"
  },
  {
    "objectID": "index.html#course-details",
    "href": "index.html#course-details",
    "title": "STAT 412: Bayesian Statistics",
    "section": "Course details",
    "text": "Course details\nInstructor: Becky Tang (she/her)\n\nOffice: WNS 214\nEmail: btang@middlebury.edu\n\nMeeting times and location: Mondays and Wednesdays 9:45-11am in WNS 011\nOffice hours: Monday 3-4pm, Tuesday 3:30-4:30pm, Friday 11am-12pm\nSyllabus (most recent update 9/1/2025): our syllabus outlines our course policies and a rough schedule. Once classes begin, you should follow the schedule and due dates found on this website."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "This page is frequently updated!\n\n\n\nWeek\nDate\nTopic\nAssignments\n\n\n\n\n1\nM 9/08\n\nWelcome!\nWhat is a statistical model?\n\n\nProblem Set 0 (due next class 9/10)\n\n\n\n\nW 9/10\n\nBayes’ rule, Bayes modeling\n\nLikelihood, prior, posterior\nCode and worksheet\n\n\n\nProblem Set 1 (due next class 9/15)\n\n\n\n2\nM 9/15\n\nBeta-Binomial model\n\nProportionality\n\nPosterior predictive distribution\n\n\nProblem Set 2 (due 9/24)\n\n\n\n\nW 9/17\n\nBayes estimators/estimates\n\nSome proofs\n\n\n\nProblem Set 2 (due 9/24)\n\n\n\n3\nM 9/22\n\nConfidence regions\nPosterior quantities and posterior predictive checks via simulation\n\nCode\n\n\n\n\n\n\nW 9/24\n\nConjugacy\nNormal sampling model\n\n\nProblem Set 3 (complete!)\nCode for HW 3\n\n\n\n4\nM 9/29\n\nMarkov chain basics\n\n\n\n\n\nW 10/01\n\nNormal model (cont.) with Gibbs sampling!\n\nData under Handouts\nCode from class\n\n\n\nFor Monday, read the article Explaining the Gibbs Sampler under Handouts and prepare to discuss!\nProblem Set 4\n\n\n\n5\nM 10/06\n\nDiscuss Explaining the Gibbs Sampler\nMCMC diagnostics\n\nCode here\n\n\n\n\n\n\nW 10/06\n\nFinish MCMC diagnostics\nJeffrey’s prior\nIntroduce Case Study 1\n\n\nWork on Case Study 1\n\n\n\n6\nM 10/13\nBecky out of town; Prof. Christian Stratton will be here in my stead!\n\nWork on Case Study 1\nWork on midterm review\n\n\nWork on Case Study 1\n\n\n\n\nW 10/15\n\nPresent Case Study 1\n\n\nStudy for midterm!\n\n\n\n7\nM 10/20\n\nBayesian hierarchical modeling\n\nHandout\n\n\n\n\n\n\nW 10/22\n\nBayesian hierarchical modeling (cont.)\n\nFind data on handouts slide\n\n\n\nProblem Set 5\n\nStarter template and data under handouts\n\n\n\n\n8\nM 10/27\n\nBayesian simple linear regression\n\nHandout\n\n\nFor Wednesday, please read:\n\nSection 7.1 of Hoff (pg. 105-7)\nPg. 337-341 of Blitzstein & Hwang (stop before Ex. 7.5.8. Skip Definition 7.5.6 and proofs if you’d like! But if you miss MGFs, now’s your chance to see them again!)\n\n\n\n\nW 10/29\n\nMultiple linear regression\n\nHandout + code\n\n\n\nProblem Set 6 (updated 10/31 for clarification on #4)\n\n\n\n9\nM 11/03\n\nMetropolis\n\nHandout\n\n\n\n\n\n\nW 11/05\n\nMetropolis (cont.) with Logistic Regression!\n\nHandout\n\nIntroduce Case Study 2\n\n\nWork on Case Study 2\n\n\n\n10\nM 11/10\n\nWork on case study 2\n\n\n\n\n\nW 11/12\n\nCase Study 2 presentations\nJAGS\n\n\nRead and work through JAGS primer\n\n\n\n11\nM 11/17\n\nReal-data analysis (ecology!)\n\n\n\n\n\nW 11/19\n\nIntroduce Case Study 3\n\n\n\n\n\n\nTHANKSGIVING\n\n\n\n12\nM 12/01\n\nIntroduce final project\nWork on Case Study 3\n\n\n\n\n\nW 12/03\n\nCase Study 3 presentations\nCRFs"
  },
  {
    "objectID": "handouts.html",
    "href": "handouts.html",
    "title": "Handouts",
    "section": "",
    "text": "Distribution sheet (updated 10/15 with Dirichlet and conjugate priors)\nExplaining the Gibbs Sampler (1992)\n\nDiscussion questions posted here!\n\nConstrained normal sampling code\nProblem Set 5 starter template:  .qmd  or  .Rmd \nData\n\n prussianHorses1 \n prussianHorses2 \n school1  Load code in as readRDS(\"filepath/school1.Rda\")\n divorce  Load code in as readRDS(\"filepath/divorce.Rda\")\n mathscores  Load code in as readRDS(\"filepath/mathscores.Rda\")\n tennis_serves  Load code in as readRDS(\"filepath/tennis_serves.Rda\")\n bbs  Load code in as readRDS(\"filepath/bbs.Rda\")\n hosp_infection \n olympic_butterfly \n ProfessorSalary \n burlington_snow \n sparrows"
  },
  {
    "objectID": "code/binom_discrete_prior.html",
    "href": "code/binom_discrete_prior.html",
    "title": "Learning about a Binomial Probability",
    "section": "",
    "text": "library(tidyverse)\nknitr::opts_chunk$set(fig.width = 6, fig.height = 3)"
  },
  {
    "objectID": "code/binom_discrete_prior.html#tidyverse-code",
    "href": "code/binom_discrete_prior.html#tidyverse-code",
    "title": "Learning about a Binomial Probability",
    "section": "Tidyverse code",
    "text": "Tidyverse code\n\n# PRIOR\ntheta &lt;- seq(0.1, 0.9, by = 0.1)\nprior1 &lt;- rep(1/9, 9)\nprior2 &lt;- c(0.05, 0.05, 0.05, 0.2, 0.3, 0.2, 0.05, 0.05, 0.05)\n\n# create data frame for visualization and wrangling\nbayes_table &lt;- data.frame(theta, prior1, prior2) \n\n# visualize different priors\nbayes_table |&gt;\n  pivot_longer(cols = 2:3, names_to = \"prior\", values_to = \"prior_probs\") |&gt;\n  mutate(theta = factor(theta)) |&gt; # for prettier visualization\n  ggplot(aes(x = theta, y = prior_probs)) + \n  geom_col() +\n  facet_wrap(~ prior) +\n  labs(x = expression(theta),\n      y = expression(f(theta)),\n      title = \"Prior\")\n\n\n\n\n\n\n\n# LIKELIHOOD\ny &lt;- 4\n## since R is vectorized:\nlike &lt;- dbinom(y, size = 11, prob = theta)\n## equivalently\n## like &lt;- choose(11, y) * theta^y * (1-theta)^(11-y)\nbayes_table &lt;- bayes_table |&gt;\n  add_column(likelihood = like) \n\n\n# MARGINAL LIKELIHOOD\nbayes_table &lt;- bayes_table |&gt;\n  mutate(product = prior2 * likelihood)\nmarg_like &lt;- sum(bayes_table$product)\n\n# POSTERIOR\nbayes_table &lt;- bayes_table |&gt;\n  mutate(posterior = product / marg_like)\nbayes_table |&gt;\n  select(theta, posterior)\n\n  theta      posterior\n1   0.1 0.006168515787\n2   0.2 0.043274594401\n3   0.3 0.086030889543\n4   0.4 0.369693507640\n5   0.5 0.377836937562\n6   0.6 0.109538817078\n7   0.7 0.006772110839\n8   0.8 0.000676165538\n9   0.9 0.000008461613\n\n# visualize prior vs posterior\n# note: could also plot in two separate plots without pivoting\nbayes_table |&gt;\n  pivot_longer(cols = c(\"prior1\", \"posterior\"), names_to = \"dist\", values_to = \"probs\") |&gt;\n  mutate(theta = factor(theta),\n         dist = factor(dist, levels = c(\"prior1\", \"posterior\"))) |&gt; # for prettier visualization\n  ggplot(aes(x = theta, y = probs)) + \n  geom_col() +\n  facet_wrap(~dist) +\n  labs(x = expression(theta),\n      y = \"Probability\",\n      title = expression(\"Comparison of \" * f(theta) * \" and \" * f(theta * \"| y\")))"
  },
  {
    "objectID": "code/binom_discrete_prior.html#base-r-code",
    "href": "code/binom_discrete_prior.html#base-r-code",
    "title": "Learning about a Binomial Probability",
    "section": "Base R code",
    "text": "Base R code\n\n## PRIOR\ntheta &lt;- seq(0.1, 0.9, by = 0.1)\nprior1 &lt;- rep(1/9, 9)\nprior2 &lt;- c(0.05, 0.05, 0.05, 0.2, 0.3, 0.2, 0.05, 0.05, 0.05)\n\nbayes_table &lt;- data.frame(theta, prior1, prior2)\n\n# Visualize prior 1\nbarplot(bayes_table$prior1, names.arg = bayes_table$theta,\n        xlab = expression(theta),\n        ylab = expression(f(theta)),\n        ylim = c(0, max(prior1) + 0.05),\n        main = \"Prior\")\n\n\n\n\n\n\n\n# LIKELIHOOD\ny &lt;- 4\nlike &lt;- dbinom(y, size = 11, prob = theta)\nbayes_table$likelihood &lt;- like\n\n# MARGINAL LIKELIHOOD\nbayes_table$product &lt;- prior1 * like\nmarg_like &lt;- sum(bayes_table$product)\n\n# POSTERIOR\nbayes_table$posterior &lt;-  bayes_table$product / marg_like\n\n# vizualize prior and posterior\npar(mfrow = c(1,2))\ny_max &lt;- max(c(prior1, bayes_table$posterior))\nbarplot(bayes_table$prior1, names.arg = bayes_table$theta,\n        xlab = expression(theta),\n        ylab = expression(f(theta)),\n        ylim = c(0, y_max + 0.05),\n        main = \"Prior\")\nbarplot(bayes_table$posterior, \n        names.arg = theta,\n        beside = T,\n        xlab = expression(theta),\n        ylab = expression(f(theta * \"| y\")),\n        ylim = c(0, y_max + 0.05),\n        main = \"Posterior\")"
  },
  {
    "objectID": "code/binom_discrete_prior.html#if-you-didnt-want-to-plot",
    "href": "code/binom_discrete_prior.html#if-you-didnt-want-to-plot",
    "title": "Learning about a Binomial Probability",
    "section": "If you didn’t want to plot",
    "text": "If you didn’t want to plot\n\nmarg_like &lt;- sum(prior1 * like)\npost &lt;- (prior1 * like)/marg_like\ncbind(theta, post)\n\n      theta          post\n [1,]   0.1 0.01893857939\n [2,]   0.2 0.13286167531\n [3,]   0.3 0.26413206805\n [4,]   0.4 0.28375828506\n [5,]   0.5 0.19333918362\n [6,]   0.6 0.08407652891\n [7,]   0.7 0.02079173713\n [8,]   0.8 0.00207596368\n [9,]   0.9 0.00002597885"
  },
  {
    "objectID": "code/proportionality.html",
    "href": "code/proportionality.html",
    "title": "Prior, likelihood, posterior, proportionality",
    "section": "",
    "text": "We often say the posterior distribution is “proportional to likelihood times prior”, where proportionality is with respect to \\(\\theta\\):\n\\[\\begin{align*}\nf_{\\theta | y}(\\theta | y) &= \\frac{f_{y | \\theta} (y | \\theta) f_{\\theta}(\\theta)}{f_{Y}(y)} \\\\\n& \\overset{\\theta}{\\propto} f_{y | \\theta} (y | \\theta) f_{\\theta}(\\theta)\n\\end{align*}\\]\nThat is, the posterior distribution is a function of \\(\\theta\\), so the marginal likelihood \\(f_{Y}(y)\\) is a constant with respect to \\(\\theta\\). It is just a scaling factor, as illustrated here:"
  },
  {
    "objectID": "handouts/bayes_est.html#theorem",
    "href": "handouts/bayes_est.html#theorem",
    "title": "Bayes estimator proofs",
    "section": "Theorem",
    "text": "Theorem\nUnder squared loss \\(L(\\theta, a) = (\\theta - a)^2\\), the Bayes estimator for \\(\\theta\\) is the posterior mean of \\(\\theta\\), \\(\\mathbb{E}[\\theta | \\mathbf{y}]\\).\n\nWant to show that \\(\\mathbb{E}[\\theta | \\mathbf{y}] = \\underset{a}{\\text{argmin}} \\ \\mathbb{E}[(\\theta - a)^2 | \\mathbf{y}]\\)\nRecall: \\(\\mathbb{E}[\\theta | \\mathbf{y}] = \\int_{\\Theta} \\theta f(\\theta | \\mathbf{y}) d\\theta\\) is a function of \\(\\mathbf{y}\\)! We’ve integrated out \\(\\theta\\)!\nAlso, for any function \\(g\\), \\(\\mathbb{E}[g(\\mathbf{y}) | \\mathbf{y}] = g(\\mathbf{y})\\).\n\nThat is, since we condition on \\(\\mathbf{y}\\) (not random), the expectation of any function of \\(\\mathbf{y}\\) is itself"
  },
  {
    "objectID": "handouts/bayes_est.html#proof-set-up",
    "href": "handouts/bayes_est.html#proof-set-up",
    "title": "Bayes estimator proofs",
    "section": "Proof set-up",
    "text": "Proof set-up\n\nWant to show that \\(m = \\underset{a}{\\text{argmin}} \\ \\mathbb{E}[ |\\theta - a| | \\mathbf{y}]\\)\nNote that the absolute value function is not differentiable, so proving a maximum/minimum cannot rely on derivatives!\nAssume that \\(\\theta\\) is continuous, so that if \\(m\\) is the posterior median, then \\(\\text{Pr}(\\theta \\geq m | \\mathbf{y}) = \\frac{1}{2} = \\text{Pr}(\\theta \\leq m | \\mathbf{y})\\).\nLet \\(a\\) be any other estimator of \\(\\theta\\).\nWe will show that\n\\[\n\\mathbb{E}[L(\\theta , a) | \\mathbf{y}] - \\mathbb{E}[L(\\theta, m) | \\mathbf{y}]  \\geq 0\n\\]\nthus demonstrating that \\(m\\) minimizes the expected loss.\nSome recap from probability: if \\(Y\\) continuous with pdf \\(f\\),\n\n\\(\\text{Pr}(Y \\leq a) = \\int_{-\\infty}^{a} f(y) dy\\)\n\\(\\text{Pr}(a \\leq Y \\leq b) = \\text{Pr}(Y\\leq b) - \\text{Pr}(Y \\leq a)\\) and these inequalities could be \\(\\leq\\) or \\(&lt;\\)"
  },
  {
    "objectID": "handouts/bayes_est.html#proof",
    "href": "handouts/bayes_est.html#proof",
    "title": "Bayes estimator proofs",
    "section": "Proof",
    "text": "Proof\nLet \\(m\\) be the posterior median, and suppose \\(a &lt; m\\) is any other estimator. Remember, \\(a\\) and \\(m\\) are constant w.r.t. \\(\\theta\\).\n\\[\n\\begin{align}\n\\mathbb{E}[L(\\theta , a) | \\mathbf{y}] & - \\mathbb{E}[L(\\theta, m) | \\mathbf{y}] = \\int_{\\Theta} |\\theta - a| f(\\theta | \\mathbf{y}) d\\theta - \\int_{\\Theta} |\\theta - m| f(\\theta | \\mathbf{y})d\\theta \\\\\n&\\class{fragment}{= \\int_{\\Theta} \\left(|\\theta - a| - |\\theta - m|\\right) f(\\theta | \\mathbf{y})d\\theta } \\\\\n&\\class{fragment}{= \\int_{-\\infty}^{a} \\left(|\\theta - a| - |\\theta - m|\\right) f(\\theta | \\mathbf{y})d\\theta + \\int_{a}^{m} \\left(|\\theta - a| - |\\theta - m|\\right) f(\\theta | \\mathbf{y})d\\theta + \\int_{m}^{\\infty} \\left(|\\theta - a| - |\\theta - m|\\right) f(\\theta | \\mathbf{y})d\\theta }\\\\\n& \\class{fragment}{= \\int_{-\\infty}^{a} ((a-\\theta) - ( m - \\theta)) f(\\theta | \\mathbf{y}) d\\theta + \\int_{a}^{m} ((\\theta - a) - (m- \\theta)) f(\\theta | \\mathbf{y}) d\\theta  +\n\\int_{m}^{\\infty} ((\\theta - a) - (\\theta - m)) f(\\theta | \\mathbf{y}) d\\theta} \\\\\n&\\class{fragment}{= \\int_{-\\infty}^{a} (a - m)  f(\\theta | \\mathbf{y}) d\\theta + \\int_{a}^{m} (2\\theta - a- m)  f(\\theta | \\mathbf{y}) d\\theta + \\int_{m}^{\\infty} (m-a) f(\\theta | \\mathbf{y}) d\\theta} \\\\\n&\\class{fragment}{\\color{orange}{\\geq}  \\int_{-\\infty}^{a} (a - m)  f(\\theta | \\mathbf{y}) d\\theta + \\int_{a}^{m} (2\\color{orange}{a} - a- m)  f(\\theta | \\mathbf{y}) d\\theta + \\int_{m}^{\\infty} (m-a) f(\\theta | \\mathbf{y}) d\\theta} \\\\\n&\\class{fragment}{= (a-m)\\text{Pr}(\\theta \\leq a | \\mathbf{y}) + \\color{purple}{(a-m)\\text{Pr}(a  &lt; \\theta \\leq m | \\mathbf{y}) }+ (m-a) \\text{Pr}(\\theta \\geq m | \\mathbf{y})} \\\\\n&\\class{fragment}{ = (a-m)\\text{Pr}(\\theta \\leq a | \\mathbf{y}) + \\color{purple}{(a-m) \\text{Pr}(\\theta \\leq m | \\mathbf{y})  - (a-m) \\text{Pr}(\\theta \\leq a | \\mathbf{y})} + (m-a) \\text{Pr}(\\theta \\geq m | \\mathbf{y}) } \\\\\n&\\class{fragment}{= (a-m) \\text{Pr}(\\theta \\leq m | \\mathbf{y}) +  (m-a) \\text{Pr}(\\theta \\geq m | \\mathbf{y})} \\\\\n&\\class{fragment}{= (a-m)\\left(\\frac{1}{2}\\right) + (m-a)\\left(\\frac{1}{2}\\right)} \\\\\n&\\class{fragment}{= (a-m)\\left(\\frac{1}{2}\\right) - (a-m)\\left(\\frac{1}{2}\\right)}\\\\\n&\\class{fragment}{= 0 \\qquad \\tiny{\\square} }\n\\end{align}\n\\]"
  },
  {
    "objectID": "handouts/bayes_est.html#proof-2",
    "href": "handouts/bayes_est.html#proof-2",
    "title": "Bayes estimator proofs",
    "section": "Proof 2",
    "text": "Proof 2\nApologies; you’ll have to do several “right clicks” until you reach the next slide.\nLet’s begin by manipulating the term we’d like to minimize: \\[\\begin{align}\n\\mathbb{E}[(\\theta - a)^2 | \\mathbf{y}] &= \\mathbb{E}[( \\color{red}{(} \\theta - \\mathbb{E}[\\theta | \\mathbf{y}]\\color{red}{)} + \\color{red}{(}\\mathbb{E}[\\theta | \\mathbf{y}]  - a\\color{red}{)})^2 | \\mathbf{y}] \\\\\n&\\class{fragment}{\\overset{\\text{FOIL}}{=} \\mathbb{E}[(\\theta - \\mathbb{E}[\\theta | \\mathbf{y}])^2 | \\mathbf{y}] + 2\\mathbb{E}[(\\theta - \\mathbb{E}[\\theta | \\mathbf{y}])(\\mathbb{E}[\\theta | \\mathbf{y}]-a) | \\mathbf{y}] + \\mathbb{E}[(\\mathbb{E}[\\theta | \\mathbf{y}]-a)^2 | \\mathbf{y}]} \\\\\n&\\class{fragment}{=\\mathbb{E}[(\\theta - \\mathbb{E}[\\theta | \\mathbf{y}])^2 | \\mathbf{y}] + 2\\mathbb{E}[(\\theta - \\mathbb{E}[\\theta | \\mathbf{y}])\\color{orange}{(\\mathbb{E}[\\theta | \\mathbf{y}]-a)} | \\mathbf{y}] + \\mathbb{E}[\\color{orange}{(\\mathbb{E}[\\theta | \\mathbf{y}]-a)^2} | \\mathbf{y}]} \\\\\n& \\class{fragment}{\\text{Note: }  \\color{orange}{\\mathbb{E}[\\theta | \\mathbf{y}]} \\text{ and } \\color{orange}{a} \\text{ are constant w.r.t } \\mathbf{y}}  \\\\\n&\\class{fragment}{=\\mathbb{E}[(\\theta - \\mathbb{E}[\\theta | \\mathbf{y}])^2 | \\mathbf{y}]  + 2 \\color{orange}{(\\mathbb{E}[\\theta | \\mathbf{y}]-a)}\\color{purple}{\\mathbb{E}[\\theta - \\mathbb{E}[\\theta | \\mathbf{y}] | \\mathbf{y}]}+ \\color{orange}{(\\mathbb{E}[\\theta | \\mathbf{y}]-a)^2}} \\\\\n&\\class{fragment}{=\\mathbb{E}[(\\theta - \\mathbb{E}[\\theta | \\mathbf{y}])^2 | \\mathbf{y}]  + 2 (\\mathbb{E}[\\theta | \\mathbf{y}]-a) \\color{purple}{( \\mathbb{E}[\\theta | \\mathbf{y}] - \\mathbb{E}[\\theta | \\mathbf{y}])} + (\\mathbb{E}[\\theta | \\mathbf{y}]-a)^2} \\\\\n&\\class{fragment}{=\\mathbb{E}[(\\theta - \\mathbb{E}[\\theta | \\mathbf{y}])^2 | \\mathbf{y}]  + (\\mathbb{E}[\\theta | \\mathbf{y}]-a)^2}\n\\end{align}\n\\]"
  },
  {
    "objectID": "handouts/bayes_est.html#theorem-1",
    "href": "handouts/bayes_est.html#theorem-1",
    "title": "Bayes estimator proofs",
    "section": "Theorem",
    "text": "Theorem\nUnder absolute loss \\(L(\\theta, a) = |\\theta - a|\\), a Bayes estimator for \\(\\theta\\) is any posterior median of \\(\\theta\\).\n\nThat is, a Bayes estimator is a function \\(\\delta(\\mathbf{y}) \\equiv m\\) such that \\(\\text{Pr}(\\theta \\leq m | \\mathbf{y}) \\geq \\frac{1}{2}\\) and \\(\\text{Pr}(\\theta \\geq m | \\mathbf{y}) \\geq \\frac{1}{2}\\).\nNote that when \\(\\theta\\) is continuous, there exists a single median."
  },
  {
    "objectID": "handouts/bayes_est.html#proof-2-cont.",
    "href": "handouts/bayes_est.html#proof-2-cont.",
    "title": "Bayes estimator proofs",
    "section": "Proof 2 (cont.)",
    "text": "Proof 2 (cont.)\nThus, \\[\n\\underset{a}{\\text{argmin}} \\ \\mathbb{E}[(\\theta - a)^2 | \\mathbf{y}] = \\underset{a}{\\text{argmin}} \\ \\mathbb{E}[(\\theta - \\mathbb{E}[\\theta | \\mathbf{y}])^2 | \\mathbf{y}]  + (\\mathbb{E}[\\theta | \\mathbf{y}]-a)^2\n\\]\n\nThe first term does not depend on \\(a\\), so cannot do anything about minimizing w.r.t \\(a\\)\nThus, focus on minimizing the second term. Minimized when \\(a = \\mathbb{E}[\\theta | \\mathbf{y}]\\).\nThus, the Bayes estimate under squared loss is the posterior mean. \\(\\tiny{\\square}\\)"
  },
  {
    "objectID": "handouts/bayes_est.html#temp",
    "href": "handouts/bayes_est.html#temp",
    "title": "Bayes estimator proofs",
    "section": "temp",
    "text": "temp"
  },
  {
    "objectID": "handouts/bayes_est.html#incremental-derivation",
    "href": "handouts/bayes_est.html#incremental-derivation",
    "title": "Bayes estimator proofs",
    "section": "Incremental Derivation",
    "text": "Incremental Derivation\n\\[\n\\begin{align}\n\\mathbb{E}[(\\theta - a)^2 \\mid \\mathbf{y}] &= \\mathbb{E}[\\big( \\color{red}{(} \\theta - \\mathbb{E}[\\theta \\mid \\mathbf{y}]\\color{red}{)} + \\color{red}{(}\\mathbb{E}[\\theta \\mid \\mathbf{y}]  - a\\color{red}{)}\\big)^2 \\mid \\mathbf{y}]\n\\end{align}\n\\]\n.fragment[ \\[\n\\begin{align}\n&= \\mathbb{E}[(\\theta - \\mathbb{E}[\\theta \\mid \\mathbf{y}])^2 \\mid \\mathbf{y}] \\\\\n&\\quad + 2\\mathbb{E}[(\\theta - \\mathbb{E}[\\theta \\mid \\mathbf{y}])(\\mathbb{E}[\\theta \\mid \\mathbf{y}]-a) \\mid \\mathbf{y}] \\\\\n&\\quad + \\mathbb{E}[(\\mathbb{E}[\\theta \\mid \\mathbf{y}]-a)^2 \\mid \\mathbf{y}]\n\\end{align}\n\\]]\n.fragment[ \\[\n\\begin{align}\n&= \\mathbb{E}[(\\theta - \\mathbb{E}[\\theta \\mid \\mathbf{y}])^2 \\mid \\mathbf{y}] \\\\\n&\\quad + 2\\mathbb{E}[(\\theta - \\mathbb{E}[\\theta \\mid \\mathbf{y}])\\color{orange}{(\\mathbb{E}[\\theta \\mid \\mathbf{y}]-a)} \\mid \\mathbf{y}] \\\\\n&\\quad + \\mathbb{E}[\\color{orange}{(\\mathbb{E}[\\theta \\mid \\mathbf{y}]-a)^2} \\mid \\mathbf{y}]\n\\end{align}\n\\]]\n.fragment[ &gt; Note: () and () are constant with respect to ()]\n.fragment[ \\[\n\\begin{align}\n&= \\mathbb{E}[(\\theta - \\mathbb{E}[\\theta \\mid \\mathbf{y}])^2 \\mid \\mathbf{y}] \\\\\n&\\quad + 2 \\color{orange}{(\\mathbb{E}[\\theta \\mid \\mathbf{y}]-a)} \\color{purple}{\\mathbb{E}[\\theta - \\mathbb{E}[\\theta \\mid \\mathbf{y}] \\mid \\mathbf{y}]} \\\\\n&\\quad + \\color{orange}{(\\mathbb{E}[\\theta \\mid \\mathbf{y}]-a)^2}\n\\end{align}\n\\]]\n.fragment[ \\[\n\\begin{align}\n&= \\mathbb{E}[(\\theta - \\mathbb{E}[\\theta \\mid \\mathbf{y}])^2 \\mid \\mathbf{y}] \\\\\n&\\quad + 2 (\\mathbb{E}[\\theta \\mid \\mathbf{y}]-a) \\color{purple}{( \\mathbb{E}[\\theta \\mid \\mathbf{y}] - \\mathbb{E}[\\theta \\mid \\mathbf{y}])} \\\\\n&\\quad + (\\mathbb{E}[\\theta \\mid \\mathbf{y}]-a)^2\n\\end{align}\n\\]]\n.fragment[ \\[\n\\begin{align}\n&= \\mathbb{E}[(\\theta - \\mathbb{E}[\\theta \\mid \\mathbf{y}])^2 \\mid \\mathbf{y}] + (\\mathbb{E}[\\theta \\mid \\mathbf{y}]-a)^2\n\\end{align}\n\\]]"
  },
  {
    "objectID": "code/post_pred_checks.html",
    "href": "code/post_pred_checks.html",
    "title": "Simulating posterior and posterior predictive distributions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(MASS)\ndata(\"Aids2\")\nFrom the Aids2 dataset from MASS, we have data on patients diagnosed with AIDS in Australia before 1 July 1991. In particular, we are interested in the outcome status of each individual at the end of the observation (alive A or dead D). We also have data on state of origin:\n# A tibble: 4 × 5\n  state     A     D     n death_rate\n  &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n1 NSW     664  1116  1780      0.627\n2 Other   107   142   249      0.570\n3 QLD      78   148   226      0.655\n4 VIC     233   355   588      0.604"
  },
  {
    "objectID": "code/post_pred_checks.html#posterior-predictive-check",
    "href": "code/post_pred_checks.html#posterior-predictive-check",
    "title": "Simulating posterior and posterior predictive distributions",
    "section": "Posterior predictive check",
    "text": "Posterior predictive check\nNow, let’s do some posterior predictive checks (PPC). One thing I might be wondering is if my assumption of iid across the 4 states is reasonble.\nFirst, let me simulate \\(R = 1000\\) new datasets of size 2843 from the PPD. For each dataset \\(r\\), I can assign state values according the observed data because I assumed state doesn’t matter (i.e. state and death status are independent).\n\nset.seed(412)\n# posterior predictive check\nR &lt;- 1000\ndf_ls &lt;- list()\nfor(r in 1:R){\n  theta_samp &lt;- rbeta(1, a + sum_y, b + n - sum_y)\n  ystar_samps &lt;- rbinom(n, size = 1, prob = theta_samp)\n  df_ls[[r]] &lt;- data.frame(status = ystar_samps) |&gt;\n    add_column(state = Aids2$state)\n}\n# Random sample of three rows in first simulated dataset:\ndf_ls[[1]] |&gt;\n  sample_n(3)\n\n  status state\n1      0   NSW\n2      1   NSW\n3      0   NSW\n\n\nVisually, we can look at how the distribution of deaths varies across the states in some of the simulated datasets:\n\n\n\n\n\n\n\n\n\nLooks pretty similar to the plot of the original data above, but humans like to see what they want to see.\nFor a more robust PPC, let’s consider the following test function \\(T(\\mathbf{y})\\): the ratio of the highest death rate and the lowest death rate among the four states.\nIn the observed data, this is 0.655/0.57 = 1.148. Let’s now obtain the values of the test function for the 1000 simualated datasets:\n\nppd_T &lt;- rep(NA, R)\nfor(r in 1:R){\n  temp &lt;- df_ls[[r]] |&gt;\n    group_by(state) |&gt;\n    summarise(death_rate = mean(status))\n  ppd_T[r] &lt;- max(temp$death_rate)/min(temp$death_rate)\n}\n\n\n\n\n\n\n\n\n\n\nThe posterior predictive probability of a ratio as or more extreme than the observed \\(T(\\mathbf{y}) = 1.148\\) is:\n\n# monte carlo approximation\npost_prob_T &lt;- mean(ppd_T &gt;= obs_T)\n\n\\[\\text{Pr}(T(\\mathbf{y}^{*} \\geq T(\\mathbf{y})) | \\mathbf{y}) = 0.088\\] This says that in 88 of the 1000 simulated datasets, I saw a test ratio value as or more extreme that what I observed in real life. To me, that seems quite low. An ideal scenario would have this posterior predictive probability be close to 0.50. Thus, it seems like maybe I should not treat the data as coming from one giant state, and instead allow for variation on the four states. That’s coming in a few weeks…"
  },
  {
    "objectID": "homework/412_hw2_r.html",
    "href": "homework/412_hw2_r.html",
    "title": "STAT 412: Problem Set 2 (R)",
    "section": "",
    "text": "library(tidyverse)\nlibrary(patchwork)\nprussian1 &lt;- read_csv(\"../handouts/prussianHorses1.csv\")\nprussian2 &lt;- read_csv(\"../handouts/prussianHorses2.csv\")\n\n\na &lt;- 1\nb &lt;- 2\nqgamma(0.95, a,b)\n\n[1] 1.497866\n\ny &lt;- prussian1$deaths\nn &lt;- length(prussian1$deaths)\ntheta_seq &lt;- seq(0.1, 5, 0.05)\nprior &lt;- dgamma(theta_seq, a, b)\na_post &lt;- a + sum(y)\nb_post &lt;- b + n\npost &lt;- dgamma(theta_seq, a_post, b_post)\nbayes_df &lt;- data.frame(theta = theta_seq, prior = prior, post = post) |&gt;\n  pivot_longer(cols= 2:3, names_to = \"distribution\", values_to = \"density\")\nbayes_df |&gt;\n  ggplot(aes(x = theta, y = density, col = distribution)) + \n  geom_line()\n\n\n\n\n\n\n\npost_prob &lt;-pgamma(0.5, a_post, b_post)\n\nThe posterior probability \\(\\text{Pr}(\\theta  &lt; 0.5 = \\mathbf{y}) = 0.0487284\\). Since this is relatively small, I would say that there is not strong evidence to suggest that the average rate of deaths by horsekick in a given year and cavalary is less than 0.5.\n\nset.seed(2)\ny_new &lt;- rnbinom(220, size = a_post, prob = (b_post)/(b_post + 1))\np1 &lt;- data.frame(y_new) |&gt;\n  ggplot(aes(x = y_new)) + \n  geom_bar() +\n  labs(x = \"Deaths\", title = \"Draws from posterior predictive distribution\")\n\np2 &lt;- prussian2 |&gt;\n  ggplot(aes(x = deaths)) +\n  geom_bar() +\n  labs(x = \"Deaths\", title = \"Held-out observations\")\n\np1 + p2"
  },
  {
    "objectID": "code/post_pred_checks.html#data",
    "href": "code/post_pred_checks.html#data",
    "title": "Simulating posterior and posterior predictive distributions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(MASS)\ndata(\"Aids2\")\n\nFrom the Aids2 dataset from MASS, we have data on patients diagnosed with AIDS in Australia before 1 July 1991. In particular, we are interested in the outcome status of each individual at the end of the observation (alive A or dead D). We also have data on state of origin:\n\n\n# A tibble: 4 × 5\n  state     A     D     n death_rate\n  &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n1 NSW     664  1116  1780      0.627\n2 Other   107   142   249      0.570\n3 QLD      78   148   226      0.655\n4 VIC     233   355   588      0.604"
  },
  {
    "objectID": "code/post_pred_checks.html#model",
    "href": "code/post_pred_checks.html#model",
    "title": "Simulating posterior and posterior predictive distributions",
    "section": "Model",
    "text": "Model\nThe response is binary, so a Bernoulli sampling model could work here. While morbid, let us consider death as success. I’ll assume that individuals are conditionally iid given the probability of death, no matter the state:\n\\[Y_{i} | \\theta \\overset{iid}{\\sim} \\text{Bern}(\\theta) \\qquad i = 1,\\ldots, 2843\\] For my prior, I don’t know much about death rates due to AIDS, so I will use a rather uninformative prior:\n\\[\\theta \\sim \\text{Beta}(2,2)\\] Because \\(n\\) is so large, I expect my posterior to be guided almost fully by the observed data.\nUnder this sampling model and prior, we know the posterior distribution of \\(\\theta\\) and the PPD for a new data point \\(Y^{*}\\) exactly. However, we will obtain samples via simulation from the posterior and PPD instead."
  },
  {
    "objectID": "code/post_pred_checks.html#simulate-posterior-and-posterior-predictive-distributions",
    "href": "code/post_pred_checks.html#simulate-posterior-and-posterior-predictive-distributions",
    "title": "Simulating posterior and posterior predictive distributions",
    "section": "Simulate posterior and posterior predictive distributions",
    "text": "Simulate posterior and posterior predictive distributions\nIn particular, I will obtain \\(S = 5000\\) samples from each distribution:\n\nset.seed(412)\nsum_y &lt;- sum(Aids2$status == \"D\")\nn &lt;- nrow(Aids2)\na &lt;- 2\nb &lt;- 2\n\nS &lt;- 5000\na_star &lt;- a + sum_y\nb_star &lt;- b + n - sum_y\n\n### OPTION 1: for loop\ntheta_samps &lt;- rep(NA, S) \nystar_samps &lt;- rep(NA, S)\nfor(s in 1:S){\n  # sample theta from posterior\n  theta &lt;- rbeta(1, a_star, b_star)\n  \n  # sample y* from data model\n  ystar &lt;- rbinom(1, size = 1, prob = theta)\n  \n  # store\n  theta_samps[s] &lt;- theta\n  ystar_samps[s] &lt;- ystar\n}\n\n### OPTION 2: leverage vectorized language\ntheta_samps &lt;- rbeta(S, a_star, b_star)\nystar_samps &lt;- rbinom(S, size = 1, prob = theta_samps)\n\nYou could run the following code to see how well the simulations approximate the exact distributions:\n\n## Compare simulated vs exact posterior quantities\n# exact posterior mean\na_star / (a_star + b_star)\n# approximate posterior mean\nmean(theta_samps)\n\n# quantile-based 95% posterior credible interval: exact\nqbeta(c(0.025, 0.975), a_star, b_star)\n# quantile-based 95% posterior credible interval: Monte Carlo approximate\nquantile(theta_samps, c(0.025, 0.975))\n\n## Compare simulated PPD to exact\n# mean and var under exact PPD\na_star / (a_star + b_star)\n(a_star / (a_star + b_star)) * (1- (a_star / (a_star + b_star)))\n\n# approximate mean and var under simulated PPD\nmean(ystar_samps)\nvar(ystar_samps)\n\nWe would work with the theta_samps vector to answer questions about \\(\\theta\\). But let’s turn to model checking."
  },
  {
    "objectID": "code/hpd_code.html",
    "href": "code/hpd_code.html",
    "title": "Code for HPD",
    "section": "",
    "text": "The density() function in R estimates the density of a random variable based off an iid sample from the density. It works by chopping up the “x-axis” or support of the density (i.e. the observed range from the iid sample) into small pieces, called coordinates. The function then estimates the density at each one of those coordinates based on the iid sample. The coordinates are the x output from density(), and the estimated density values are the y output from the function. These are accessed accessed via the $ symbol when the returned value from the function is stored as a variable (dens below).\n\n# theta_samps: vector of random samples of theta\n# cred_mass: gamma (e.g. 0.95)\n# grid_size: the bandwidth/number of coordinates used to estimate density\nget_hpd &lt;- function(theta_samps, cred_mass, grid_size = 10000) {\n  # Estimate true posterior density of theta using kernel density estimation.\n  dens &lt;- density(theta_samps, n = grid_size)\n  \n  dx &lt;- diff(dens$x[1:2])  \n  \n  ord &lt;- order(dens$y, decreasing = TRUE)\n  \n  cum_prob &lt;- cumsum(dens$y[ord]) * dx\n  \n  id &lt;- min(which(cum_prob &gt;= cred_mass))\n  dens_cutoff &lt;- dens$y[ord][id]\n  \n  inside &lt;- dens$y &gt;= dens_cutoff\n  \n  hpd_regions &lt;- list() \n  in_region &lt;- FALSE\n  for (i in seq_along(inside)) {\n    if (inside[i] && !in_region) { \n      start &lt;- dens$x[i] \n      in_region &lt;- TRUE \n    } else if ( (!inside[i]) & in_region) { \n      end &lt;- dens$x[i - 1]\n      hpd_regions[[length(hpd_regions) + 1]] &lt;- c(start, end)\n      in_region &lt;- FALSE \n    }\n  }\n  \n  if (in_region) {\n    hpd_regions[[length(hpd_regions) + 1]] &lt;- c(start, dens$x[length(dens$x)])\n  }\n  \n  return(hpd_regions)\n}"
  },
  {
    "objectID": "code/gibbs_normal_model.html",
    "href": "code/gibbs_normal_model.html",
    "title": "Gibbs sampler: Normal Model",
    "section": "",
    "text": "We have data on the amount of time (in hours) a sample of students from a high school spent studying during a two-day reading period before exams. We will model the data as:\n\\[ \\begin{align*}\nY_{i} \\mid \\theta, \\sigma^2 &\\overset{iid}{\\sim} N(\\theta, \\sigma^2) \\qquad i = 1,\\ldots,n \\\\\n\\theta &\\sim N(\\mu_{0}, \\sigma_{0}^2) \\\\\n\\phi &\\sim \\text{Gamma}(a_{0}, b_{0})\n\\end{align*}\\]\nwhere \\(\\phi = \\frac{1}{\\sigma^2}\\). We have to fill out our priors for \\(\\theta\\) and \\(\\phi\\) to fully specify the statistical model before seeing the data. Let’s do that together!\n\nmu_0 &lt;- 5\ns2_0 &lt;- 4\na_0 &lt;- 5\nb_0 &lt;- 15\n\n# demonstrate how I might do prior elicitation\nhist(sqrt(1/(rgamma(10000, a_0, b_0))))"
  },
  {
    "objectID": "code/gibbs_normal_model.html#prior-specification",
    "href": "code/gibbs_normal_model.html#prior-specification",
    "title": "Gibbs sampler: Normal Model",
    "section": "",
    "text": "We have data on the amount of time (in hours) a sample of students from a high school spent studying during a two-day reading period before exams. We will model the data as:\n\\[ \\begin{align*}\nY_{i} \\mid \\theta, \\sigma^2 &\\overset{iid}{\\sim} N(\\theta, \\sigma^2) \\qquad i = 1,\\ldots,n \\\\\n\\theta &\\sim N(\\mu_{0}, \\sigma_{0}^2) \\\\\n\\phi &\\sim \\text{Gamma}(a_{0}, b_{0})\n\\end{align*}\\]\nwhere \\(\\phi = \\frac{1}{\\sigma^2}\\). We have to fill out our priors for \\(\\theta\\) and \\(\\phi\\) to fully specify the statistical model before seeing the data. Let’s do that together!\n\nmu_0 &lt;- 5\ns2_0 &lt;- 4\na_0 &lt;- 5\nb_0 &lt;- 15\n\n# demonstrate how I might do prior elicitation\nhist(sqrt(1/(rgamma(10000, a_0, b_0))))"
  },
  {
    "objectID": "code/gibbs_normal_model.html#data",
    "href": "code/gibbs_normal_model.html#data",
    "title": "Gibbs sampler: Normal Model",
    "section": "Data",
    "text": "Data\nNow we get to see the data:\n\ny &lt;- readRDS(\"~/Desktop/STAT 412/data/school1.Rda\")\ndata.frame(hours = y) |&gt;\n  ggplot(aes(x = hours)) +\n  geom_histogram(bins = 15)\n\n\n\n\n\n\n\nybar &lt;- mean(y)\nn &lt;- length(y)"
  },
  {
    "objectID": "code/gibbs_normal_model.html#gibbs-sampler",
    "href": "code/gibbs_normal_model.html#gibbs-sampler",
    "title": "Gibbs sampler: Normal Model",
    "section": "Gibbs sampler",
    "text": "Gibbs sampler\n\nset.seed(412)\n### GIBBS sampler\nS &lt;- 5000\n\n# will generate a bunch of samples, need to store them somewhere!\nTHETA &lt;- rep(NA, S)\nS2 &lt;- rep(NA, S)\n  \n# initialize the sampler \n# since sampling precision first, initialize value of theta\ntheta &lt;- 2\n\nfor (s in 1:S){\n  # sample phi from full conditional\n  b_n &lt;- 0.5*sum( (y - theta)^2) + b_0\n  a_n &lt;- 0.5*n + a_0\n  phi &lt;- rgamma(1, a_n, b_n)\n  \n  # convert phi to s2\n  s2 &lt;- 1/phi\n  \n  # sample theta from full conditional\n  s2_n &lt;- 1/(1/s2_0 + n / s2)\n  mu_n &lt;- s2_n * (n * ybar/s2 + mu_0/s2_0)\n  theta &lt;- rnorm(1, mu_n, sqrt(s2_n))\n\n  # store my samples\n  THETA[s] &lt;- theta\n  S2[s] &lt;- s2\n}\n\n\nSeeing the sampling"
  },
  {
    "objectID": "code/gibbs_normal_model.html#traceplots-and-posterior-quantities",
    "href": "code/gibbs_normal_model.html#traceplots-and-posterior-quantities",
    "title": "Gibbs sampler: Normal Model",
    "section": "Traceplots and posterior quantities",
    "text": "Traceplots and posterior quantities\nTrace plots of markov chains: line plot of simulated draws of parameter against iteration. In theory, the Metropolis and Gibbs sampling algorithms will produce simulated draws that converge to the posterior distribution of interest. But in typical practice, it may take a number of iterations before the simulation values are close to the posterior distribution. So in general it is recommended that one run the algorithm for a number of “burn-in” iterations before one collects iterations for inference.\nWe want nice “caterpillar” looking traceplots. This would suggest convergence!\n\nplot(THETA, xlab = \"Iteration\", ylab = \"theta\", type = \"l\", main = \"Traceplot\")\n\n\n\n\n\n\n\nplot(S2, xlab = \"Iteration\", ylab = \"sigma2\", type = \"l\", main = \"Traceplot\")\n\n\n\n\n\n\n\n\nThat crazy large sampled \\(\\sigma^2\\) at the beginning is a product of intialization and exploring the state space; we almost surely haven’t entered stationary distribution yet. Let’s go ahead and throw away half of our values as burn-in.\n\n# throw away some values as burn-in\nTHETA &lt;- THETA[-c(1:round(S/2))]\nS2 &lt;- S2[-c(1:round(S/2))]\n\nLet’s re-examine the traceplots post burn-in. From experience, these are beautiful looking traceplots!\n\npost_df &lt;- data.frame(theta = THETA, s2 = S2)\npost_df |&gt;\n  mutate(iteration = row_number()) |&gt;\n  pivot_longer(cols = 1:2, names_to = \"param\", values_to = \"value\") |&gt;\n  ggplot(aes(x = iteration, y = value)) +\n  geom_line() +\n  facet_wrap(~param, scales = \"free\") +\n  labs(\"Traceplots after burn-in\")\n\n\n\n\n\n\n\n\nWe should only estimate quantities after we’ve converged (i.e. after burn-in). In this case, we can obtain estimates of posterior quantities like usual:\n\n# estimated posterior mean of theta\nmean(THETA)\n\n[1] 8.967482\n\n# estimated posterior mean of sigma\nmean(sqrt(S2))\n\n[1] 3.493671\n\n## estimated CIs\nquantile(THETA, c(0.025, 0.975))\n\n     2.5%     97.5% \n 7.629652 10.265034 \n\nquantile(sqrt(S2), c(0.025, 0.975))\n\n    2.5%    97.5% \n2.787186 4.464605"
  },
  {
    "objectID": "code/gibbs_normal_model.html#diving-into-joint-density",
    "href": "code/gibbs_normal_model.html#diving-into-joint-density",
    "title": "Gibbs sampler: Normal Model",
    "section": "Diving into joint density",
    "text": "Diving into joint density\nWe can obtain a contour plot of the joint density using the samples obtained from Gibbs:\n\n\n\n\n\n\n\n\n\nWe can see how we “marginalize out” one parameter to get the posterior density of the other. To obtain marginals, we simply grab/isolate the parameter of interest.\n\n\n\n\n\n\n\n\n\n\nhist(THETA, main = \"Marginal posterior histogram\", xlab = \"theta\")\n\n\n\n\n\n\n\nhist(S2, main = \"Marginal posterior histogram\", xlab = \"s2\")"
  },
  {
    "objectID": "code/gibbs_normal_model.html#chains",
    "href": "code/gibbs_normal_model.html#chains",
    "title": "Gibbs sampler: Normal Model",
    "section": "Chains",
    "text": "Chains\nIn this example, we have illustrated running a single “chain” where one has a single starting value and we simulated draws over \\(S\\) iterations. It is possible that the behavior of the MCMC sample will depend on the choice of starting value. So a general recommendation is to run the MCMC algorithm several times using different starting values. In this case, one will have multiple MCMC chains and combine them.\nWhen we code samplers by hand in this course, we will almost always run a single chain to make our lives easier. However, when we turn to software that implements the MCMC for us, it’s very easy to specify multiple chains!"
  },
  {
    "objectID": "code/gibbs_normal_model_sampler_code.html",
    "href": "code/gibbs_normal_model_sampler_code.html",
    "title": "Gibbs Sampler: Normal Model",
    "section": "",
    "text": "set.seed(412)\n### GIBBS sampler\nS &lt;- 5000\n\n# will generate a bunch of samples, need to store them somewhere!\nTHETA &lt;- rep(NA, S)\nS2 &lt;- rep(NA, S)\n  \n# initialize the sampler \n# since sampling precision first, initialize value of theta\ntheta &lt;- 2\n\nfor (s in 1:S){\n  # sample phi from full conditional\n  b_n &lt;- 0.5*sum((y - theta)^2) + b_0\n  a_n &lt;- 0.5*n + a_0\n  phi &lt;- rgamma(1, a_n, b_n)\n  \n  # convert phi to s2\n  s2 &lt;- 1/phi\n  \n  # sample theta from full conditional\n  s2_n &lt;- 1/(1/s2_0 + n / s2)\n  mu_n &lt;- s2_n * (n * ybar/s2 + mu_0/s2_0)\n  theta &lt;- rnorm(1, mu_n, sqrt(s2_n))\n\n  # store my samples\n  THETA[s] &lt;- theta\n  S2[s] &lt;- s2\n}"
  },
  {
    "objectID": "code/gibbs_normal_model_walkthrough.html",
    "href": "code/gibbs_normal_model_walkthrough.html",
    "title": "Gibbs sampler: Normal Model",
    "section": "",
    "text": "We have data on the amount of time (in hours) a sample of students from a high school spent studying during a two-day reading period before exams. We will model the data as:\n\\[ \\begin{align*}\nY_{i} \\mid \\theta, \\sigma^2 &\\overset{iid}{\\sim} N(\\theta, \\sigma^2) \\qquad i = 1,\\ldots,n \\\\\n\\theta &\\sim N(\\mu_{0}, \\sigma_{0}^2) \\\\\n\\phi &\\sim \\text{Gamma}(a_{0}, b_{0})\n\\end{align*}\\]\nwhere \\(\\phi = \\frac{1}{\\sigma^2}\\). We have to fill out our priors for \\(\\theta\\) and \\(\\phi\\) to fully specify the statistical model before seeing the data. Let’s do that together!\n\nmu_0 &lt;- 6\ns2_0 &lt;- 2.5\na_0 &lt;- 5\nb_0 &lt;- 100\n\n# demonstrate how I might do prior elicitation\n# hist(sqrt(1/(rgamma(10000, a_0, b_0))))"
  },
  {
    "objectID": "code/gibbs_normal_model_walkthrough.html#prior-specification",
    "href": "code/gibbs_normal_model_walkthrough.html#prior-specification",
    "title": "Gibbs sampler: Normal Model",
    "section": "",
    "text": "We have data on the amount of time (in hours) a sample of students from a high school spent studying during a two-day reading period before exams. We will model the data as:\n\\[ \\begin{align*}\nY_{i} \\mid \\theta, \\sigma^2 &\\overset{iid}{\\sim} N(\\theta, \\sigma^2) \\qquad i = 1,\\ldots,n \\\\\n\\theta &\\sim N(\\mu_{0}, \\sigma_{0}^2) \\\\\n\\phi &\\sim \\text{Gamma}(a_{0}, b_{0})\n\\end{align*}\\]\nwhere \\(\\phi = \\frac{1}{\\sigma^2}\\). We have to fill out our priors for \\(\\theta\\) and \\(\\phi\\) to fully specify the statistical model before seeing the data. Let’s do that together!\n\nmu_0 &lt;- 6\ns2_0 &lt;- 2.5\na_0 &lt;- 5\nb_0 &lt;- 100\n\n# demonstrate how I might do prior elicitation\n# hist(sqrt(1/(rgamma(10000, a_0, b_0))))"
  },
  {
    "objectID": "code/gibbs_normal_model_walkthrough.html#data",
    "href": "code/gibbs_normal_model_walkthrough.html#data",
    "title": "Gibbs sampler: Normal Model",
    "section": "Data",
    "text": "Data\nNow we get to see the data:\n\ny &lt;- readRDS(\"~/Desktop/STAT 412/data/school1.Rda\")\ndata.frame(hours = y) |&gt;\n  ggplot(aes(x = hours)) +\n  geom_histogram(bins = 15)\n\n\n\n\n\n\n\nybar &lt;- mean(y)\nn &lt;- length(y)"
  },
  {
    "objectID": "code/gibbs_normal_model_walkthrough.html#gibbs-sampler",
    "href": "code/gibbs_normal_model_walkthrough.html#gibbs-sampler",
    "title": "Gibbs sampler: Normal Model",
    "section": "Gibbs sampler",
    "text": "Gibbs sampler\n\nset.seed(412)\n### GIBBS sampler\nS &lt;- 5000\n\n# will generate a bunch of samples, need to store them somewhere!\nTHETA &lt;- rep(NA, S)\nS2 &lt;- rep(NA, S)\n  \n# initialize the sampler \n# since sampling precision first, initialize value of theta\ntheta &lt;- 2\n\nfor (s in 1:S){\n  # sample phi from full conditional\n  b_n &lt;- 0.5*sum( (y - theta)^2) + b_0\n  a_n &lt;- 0.5*n + a_0\n  phi &lt;- rgamma(1, a_n, b_n)\n  \n  # convert phi to s2\n  s2 &lt;- 1/phi\n  \n  # sample theta from full conditional\n  s2_n &lt;- 1/(1/s2_0 + n / s2)\n  mu_n &lt;- s2_n * (n * ybar/s2 + mu_0/s2_0)\n  theta &lt;- rnorm(1, mu_n, sqrt(s2_n))\n\n  # store my samples\n  THETA[s] &lt;- theta\n  S2[s] &lt;- s2\n}\n\n\nSeeing the sampling"
  },
  {
    "objectID": "code/gibbs_normal_model_walkthrough.html#traceplots-and-posterior-quantities",
    "href": "code/gibbs_normal_model_walkthrough.html#traceplots-and-posterior-quantities",
    "title": "Gibbs sampler: Normal Model",
    "section": "Traceplots and posterior quantities",
    "text": "Traceplots and posterior quantities\nTrace plots of markov chains: line plot of simulated draws of parameter against iteration. In theory, the Metropolis and Gibbs sampling algorithms will produce simulated draws that converge to the posterior distribution of interest. But in typical practice, it may take a number of iterations before the simulation values are close to the posterior distribution. So in general it is recommended that one run the algorithm for a number of “burn-in” iterations before one collects iterations for inference.\nWe want nice “caterpillar” looking traceplots. This would suggest convergence!\n\nplot(THETA, xlab = \"Iteration\", ylab = \"theta\", type = \"l\", main = \"Traceplot\")\n\n\n\n\n\n\n\nplot(S2, xlab = \"Iteration\", ylab = \"sigma2\", type = \"l\", main = \"Traceplot\")\n\n\n\n\n\n\n\n\nThat crazy large sampled \\(\\sigma^2\\) at the beginning is a product of intialization and exploring the state space; we almost surely haven’t entered stationary distribution yet. Let’s go ahead and throw away half of our values as burn-in.\n\n# throw away some values as burn-in\nTHETA &lt;- THETA[-c(1:round(S/2))]\nS2 &lt;- S2[-c(1:round(S/2))]\n\nLet’s re-examine the traceplots post burn-in. From experience, these are beautiful looking traceplots!\n\npost_df &lt;- data.frame(theta = THETA, s2 = S2)\npost_df |&gt;\n  mutate(iteration = row_number()) |&gt;\n  pivot_longer(cols = 1:2, names_to = \"param\", values_to = \"value\") |&gt;\n  ggplot(aes(x = iteration, y = value)) +\n  geom_line() +\n  facet_wrap(~param, scales = \"free\") +\n  labs(\"Traceplots after burn-in\")\n\n\n\n\n\n\n\n\nWe should only estimate quantities after we’ve converged (i.e. after burn-in). In this case, we can obtain estimates of posterior quantities like usual:\n\n# estimated posterior mean of theta\nmean(THETA)\n\n[1] 8.693283\n\n# estimated posterior mean of sigma\nmean(sqrt(S2))\n\n[1] 4.19726\n\n## estimated CIs\nquantile(THETA, c(0.025, 0.975))\n\n     2.5%     97.5% \n 7.177723 10.142940 \n\nquantile(sqrt(S2), c(0.025, 0.975))\n\n    2.5%    97.5% \n3.355402 5.368383"
  },
  {
    "objectID": "code/gibbs_normal_model_walkthrough.html#diving-into-joint-density",
    "href": "code/gibbs_normal_model_walkthrough.html#diving-into-joint-density",
    "title": "Gibbs sampler: Normal Model",
    "section": "Diving into joint density",
    "text": "Diving into joint density\nWe can obtain a contour plot of the joint density using the samples obtained from Gibbs:\n\n\n\n\n\n\n\n\n\nWe can see how we “marginalize out” one parameter to get the posterior density of the other. To obtain marginals, we simply grab/isolate the parameter of interest.\n\n\n\n\n\n\n\n\n\n\nhist(THETA, main = \"Marginal posterior histogram\", xlab = \"theta\")\n\n\n\n\n\n\n\nhist(S2, main = \"Marginal posterior histogram\", xlab = \"s2\")"
  },
  {
    "objectID": "code/gibbs_normal_model_walkthrough.html#chains",
    "href": "code/gibbs_normal_model_walkthrough.html#chains",
    "title": "Gibbs sampler: Normal Model",
    "section": "Chains",
    "text": "Chains\nIn this example, we have illustrated running a single “chain” where one has a single starting value and we simulated draws over \\(S\\) iterations. It is possible that the behavior of the MCMC sample will depend on the choice of starting value. So a general recommendation is to run the MCMC algorithm several times using different starting values. In this case, one will have multiple MCMC chains and combine them.\nWhen we code samplers by hand in this course, we will almost always run a single chain to make our lives easier. However, when we turn to software that implements the MCMC for us, it’s very easy to specify multiple chains!"
  },
  {
    "objectID": "handouts/constrained_normal.html",
    "href": "handouts/constrained_normal.html",
    "title": "Constrained Normal Sampling Code",
    "section": "",
    "text": "# n = number of random samples \n# mu = mean of normal \n# sd = std. dev. normal \n# a = lower constraint (can be -Inf or a real number) \n# b = upper constraint (can be Inf or a real number)\n\nrnorm_constrained &lt;- function(n, mu, sd, a, b){\n  u &lt;- runif(n, pnorm(a, mu,sd), pnorm(b, mu, sd)) \n  qnorm(u, mu, sd) \n}"
  },
  {
    "objectID": "code/mixture_normals.html",
    "href": "code/mixture_normals.html",
    "title": "Mixture of Normals",
    "section": "",
    "text": "The density we’re interest in sampling from is \\[f(\\theta) = 0.45 N\\left(\\theta; -3, \\frac{1}{4}\\right) + 0.10 N\\left(\\theta; 0, \\frac{1}{4}\\right) +0.45 N\\left(\\theta; 3, \\frac{1}{4}\\right)\\] This is a mixutre of three Normals. You’ve seen your first mixture distribution in this class on the previous homework!\nWe can easily evaluate this distribution at a grid of \\(\\theta\\) values.\n\nw_prob &lt;- c(0.45, 0.1, 0.45)\nmu_vec &lt;- c(-3, 0, 3)\nsigma_vec &lt;- c(0.5, 0.5,0.5)\n\n# true density\ntheta_vec &lt;- seq(-10, 10, 0.01)\nmixture_dens &lt;- rep(NA, length(theta_vec))\nfor(i in 1:length(theta_vec)){\n  mixture_dens[i] &lt;- sum(dnorm(theta_vec[i], mu_vec, sigma_vec)*w_prob)\n}"
  },
  {
    "objectID": "code/mixture_normals.html#mixture-of-normals-density",
    "href": "code/mixture_normals.html#mixture-of-normals-density",
    "title": "Mixture of Normals",
    "section": "",
    "text": "The density we’re interest in sampling from is \\[f(\\theta) = 0.45 N\\left(\\theta; -3, \\frac{1}{4}\\right) + 0.10 N\\left(\\theta; 0, \\frac{1}{4}\\right) +0.45 N\\left(\\theta; 3, \\frac{1}{4}\\right)\\] This is a mixutre of three Normals. You’ve seen your first mixture distribution in this class on the previous homework!\nWe can easily evaluate this distribution at a grid of \\(\\theta\\) values.\n\nw_prob &lt;- c(0.45, 0.1, 0.45)\nmu_vec &lt;- c(-3, 0, 3)\nsigma_vec &lt;- c(0.5, 0.5,0.5)\n\n# true density\ntheta_vec &lt;- seq(-10, 10, 0.01)\nmixture_dens &lt;- rep(NA, length(theta_vec))\nfor(i in 1:length(theta_vec)){\n  mixture_dens[i] &lt;- sum(dnorm(theta_vec[i], mu_vec, sigma_vec)*w_prob)\n}"
  },
  {
    "objectID": "code/mixture_normals.html#monte-carlo-sampling",
    "href": "code/mixture_normals.html#monte-carlo-sampling",
    "title": "Mixture of Normals",
    "section": "Monte Carlo sampling",
    "text": "Monte Carlo sampling\nIf we want to sample from this mixture distribution, we can use Monte Calo sampling! For \\(s = 1,\\ldots, S\\):\n\nSample a value \\(w^{(s)} = \\{1,2,3\\}\\) according to mixture weights \\(\\{0.45, 0.10, 0.45\\}\\)\nGiven the value of \\(w\\), sample \\(\\theta^{(s)}\\) from the corresponding Normal. For example:\n\n\\[\\theta^{(s)} | w^{(s)} = 1 \\sim N\\left (-3, \\frac{1}{4}\\right)\\] Note this is indeed Monte Carlo sampling because we are drawing independent random sample!\nLet’s draw 1000 MC samples. A normalized histogram of the samples is shown below, along with the true density overlaid in orange:\n\nset.seed(1)\n# monte carlo\nS &lt;- 1000\nd_samp &lt;- sample(1:3, S, replace = T, prob = w_prob)\nhist(rnorm(S, mu_vec[d_samp], sigma_vec[d_samp]), freq = F, breaks =\n       20, main = \"Mixture of Normals\", xlab = \"theta\")\nlines(theta_vec, mixture_dens, type = \"l\", col = \"orange\")"
  },
  {
    "objectID": "code/mixture_normals.html#mcmc-sampling",
    "href": "code/mixture_normals.html#mcmc-sampling",
    "title": "Mixture of Normals",
    "section": "MCMC sampling",
    "text": "MCMC sampling\nWe can also obtain samples from this distribution via Gibbs sampling (i.e. Markov Chain Monte Carlo)! Note that even though we’re not working with a posterior, we can still perform Gibbs Sampling if we have more than one parameter of interest. In this case, why don’t I iterate between 1) sampling a \\(\\theta\\) value from its full conditional and 2) sampling a mixture component \\(w\\) value from its full conditional? That is, for \\(s =1,\\ldots, S\\):\n\nSample \\(w^{(s)} \\sim f(w | \\theta^{s-1})\\)\nSample \\(\\theta^{(s)} \\sim f(\\theta | w^{(s)})\\)\n\nConvince yourself that this sampling scheme is different from the previous!\nWe already have the distrution for sampling in step 2. So we just need to derive the full conditional for \\(w\\)! Let’s do that together.\n\nGibbs sampler\nLet’s run our sampler for \\(S=5000\\) iterations, then take a look at the traceplot and marginal histogram for \\(\\theta\\). Note: even though we’re sampling \\(w\\)’s along the way, I don’t actually care about them (they are latent variables). So I don’t bother storing them!\n\nseed &lt;- 10\nS &lt;- 5000\nset.seed(seed)\ntheta &lt;- -2\nTHETA &lt;- rep(NA, S)\nfor(s in 1:S){\n  # sample w\n  prob_vec_unnorm &lt;- dnorm(theta, mu_vec, sigma_vec) * w_prob\n  prob_vec_norm &lt;- prob_vec_unnorm/sum(prob_vec_unnorm)\n  w &lt;- sample(1:3, size = 1, prob = prob_vec_norm)\n  \n  # sample theta\n  theta &lt;- rnorm(1, mu_vec[w], sigma_vec[w])\n  THETA[s] &lt;- theta\n}\npar(mfrow = c(1, 2))\nplot(THETA, type = \"l\", main = \"Traceplot\", xlab = \"iteration\")\nhist(THETA, freq = F, main = \"\", xlab = expression(theta))\n\n\n\n\n\n\n\n\nWhat are we noticing?\nWell, we did say that we should throw out the first chunk of iterations to burn-in. So let me throw out the first half and re-visualize:\n\npar(mfrow = c(1, 2))\nTHETA_burned &lt;- THETA[-c(1:(S/2))]\nplot(THETA_burned, type = \"l\",  main = \"Traceplot\", xlab = \"iteration (after burn-in)\")\nhist(THETA_burned, freq = F, main = \"\", xlab = expression(theta))\n\n\n\n\n\n\n\n\nYikes!! That sure is misleading!!!! After burn-in, it seems like my density has converged to a unimodal distribution. What’s happening here?\nLet’s talk about convergence, mixing, and autocorrelation!\n\n\nGibbs, take 2\nLet’s now run the chain a lot longer, this time for \\(S = 20000\\) iterations.\n\n\n\n\n\n\n\n\n\nThat’s much better! Of course, in real life, we don’t know what the desire (posterior) density should look like. But this goes to show that you should, if computationally feasible, run your chain for a long time and perhaps for many different \\(S\\) values."
  },
  {
    "objectID": "code/mixture_normals.html#functions-for-mcmc-diagnostics",
    "href": "code/mixture_normals.html#functions-for-mcmc-diagnostics",
    "title": "Mixture of Normals",
    "section": "Functions for MCMC diagnostics",
    "text": "Functions for MCMC diagnostics\n\nAutocorrelation\nThe R function for examining autocorrelation is acf(), and you pass in a vector of samples:\n\nacf(THETA_burned)\n\n\n\n\n\n\n\n\nThe horizontal blue linee give the values beyond which the autocorrelations are (statistically) significantly different from 0. So you’d like ACF values within the blue bands.\nIf you just want the sample lag \\(t\\) ACF value, you can access it as follows:\n\nacf_out &lt;- acf(THETA_burned, plot = T)\n\n\n\n\n\n\n\n# lag-0 is at index 1\n# lag-1 is at index 2\nacf_out$acf[2]\n\n[1] 0.9685008\n\n\n\n\nEffective sample size\nWe can obtain \\(n_{eff}\\) using the effectiveSize() function from the R package coda (install it first).\n\n# yikes\ncoda::effectiveSize(THETA_burned) \n\n    var1 \n6.235923"
  },
  {
    "objectID": "case_study.html",
    "href": "case_study.html",
    "title": "Case studies",
    "section": "",
    "text": "Your second case study will once again be performed in pairs of Becky’s choosing! Each group will submit 1 report in the form of both a .Rmd (or .qmd) and a knitted/rendered PDF. These will be submitted to Canvas (not in-person) by Wednesday, 11/12 at 11:59pm.\nI anticipate you will run into questions/concerns – this is good. Don’t hesitate to come ask Becky!\nThe description of the case study and the data are found here:\n\nDescription\nData:  federalist_papers \nOptional .Rmd template:  caseStudy2 \n\n\n\n\nEach group will give a brief 5 minute presentation of their work to the class on 11/12. Presentation order will be randomized.\nYour presentation should be accompanied by a brief set of slides. As we are all aware of the data and the sampling model, these slides should focus mostly on your approach to answering the research question, as well as results (with interpretation).\n\nThink about embedding LaTex equations and R plots for your statistical model. These should be presented in an effective manner.\nYour presentation of results should answer the research question in an effective manner. Please include the required (at least one) visualization that answers the research question.\n\nYou should be prepared to answer questions from the audience. You should also be prepared to ask questions of presenters.\nYou don’t need to submit your slides for this case study! Just be prepared to present from a laptop!\nThis presentation is worth 5 points, in addition to the 40 points of the written portion. However, the presentation will be graded on an individual basis, rather than the entire group. A general rubric is:\n\n1 point: slides and presenter effectively share approach to answering the research question\n1 point: slides and presenter effectively share results that answer the research question(s)\n\nFor results tables/plots/CIs, etc: this includes describing what you’re showing (e.g. what exactly are you visualizing or calculating) and then interpreting and telling us the important things to take away from that item.\n\n1 point: speaker appears practiced and shares speaking time.\n\nBecause this presentation is short and you’re so close to your model, you shouldn’t be reading off any sort of notes!\n\n0.5 point: speaker is able to thoughtfully answer questions from audience\n1.5 points: asks at least one interesting/thoughtful/relevant question to other speakers, or gives at least one piece of useful and implementable feedback for improvement before submission of the written report\n\n“Effective” is a broad term that I use to cover:\n\nPresenting equations/distributions/slides in a logical order\nHaving font (both text and on figures/tables) be large enough for the audience to see\nSlides have enough text to be generally understood without a speaker, but each slide’s content is elevated/made complete by the speaker’s additions/commentary\nNo errors in terms of spelling, typesetting, and notation"
  },
  {
    "objectID": "case_study.html#case-study-1",
    "href": "case_study.html#case-study-1",
    "title": "Case studies",
    "section": "Case study 1",
    "text": "Case study 1\nYour first case study will be performed in pairs! You should work together; don’t just divy up the work. A large part of modeling is bouncing ideas back and forth and checking in to make sure things “make sense”. Each group will submit 1 report in the form of both a .Rmd and a knitted/rendered PDF. These will be submitted to Canvas (not in-person) by beginning of class 10/15.\nThe description of the case study and the data are found here:\n\nDescription\nData:  ItalyMarriageRates \nOptional .Rmd template:  caseStudy1 \n\n\nPresentation\n\nEach group will give a brief 5 minute presentation of their work to the class on 10/15. Presentation order will be randomized.\nYour presentation should be accompanied by a brief set of slides. As we are all aware of the data, these slides should focus mostly on describing your statistical model and how you arrived at it, as well as results (with interpretation).\n\nThink about embedding LaTex equations and R plots for your statistical model. These should be presented in an effective manner.\nYour presentation of results should answer the research question in an effective manner. Does that mean you’ll present a table of posterior summary quantities, a plot of a posterior density, or something else?\n\nYou should be prepared to answer questions from the audience. You should also be prepared to ask questions of presenters.\nYou don’t need to submit your slides for this case study! Just be prepared to present from a laptop!\nThis presentation is worth 5 points, in addition to the 35 points of the written portion. However, the presentation will be graded on an individual basis, rather than the entire group. A general rubric is:\n\n1 point: slides effectively share statistical model.\n1 point: slides effectively share results that answer the research question(s)\n1 point: speaker appears practiced and shares speaking time.\n\n“Appearing practiced” also encompasses being as close to the 5-minute duration as possible!\nBecause this presentation is short and you’re so close to your model, you shouldn’t be reading off any sort of notes!\n\n1 point: speaker is able to thoughtfully answer questions from audience\n1 point: asks at least one interesting/thoughtful/relevant question to other speakers\n\n“Effective” is a broad term that I use to cover:\n\nPresenting equations/distributions/slides in a logical order\nHaving font (both text and on figures/tables) be large enough for the audience to see\nSlides have enough text to be generally understood without a speaker, but each slide’s content is elevated/made complete by the speaker’s additions/commentary\nMinimal errors in terms of spelling and typesetting"
  },
  {
    "objectID": "case_study/case_study_1_template.html",
    "href": "case_study/case_study_1_template.html",
    "title": "STAT 412: Case Study 1",
    "section": "",
    "text": "DELETE ALL THE TEXT PROVIDED BY BECKY BEFORE SUBMITTING!\n# if you need packages, load them here\n\n# the following line of code sets the size of the figures when knitting for all code chunks. \n# You can also change the figure size in each specific chunk's header\nknitr::opts_chunk$set(fig.height = 3, fig.width = 5)\n\n# load your data here\n# Once you've set your file path, change the R chunk header to eval = TRUE\nmarriage &lt;- read_csv()"
  },
  {
    "objectID": "case_study/case_study_1_template.html#model-description",
    "href": "case_study/case_study_1_template.html#model-description",
    "title": "STAT 412: Case Study 1",
    "section": "Model description",
    "text": "Model description\nClearly state your model (Address questions 1 and 2). I encourage you to type up your model in math notation using Latex. For example:\n\\(Y_{1}, \\ldots, Y_{n} |\\theta \\overset{iid}{\\sim} f(y | \\theta)\\)\nIf you do not know how, that’s okay! Just let me know and I will be happy to help or point you towards some resources."
  },
  {
    "objectID": "case_study/case_study_1_template.html#implementation",
    "href": "case_study/case_study_1_template.html#implementation",
    "title": "STAT 412: Case Study 1",
    "section": "Implementation",
    "text": "Implementation\nClearly state how you will implement your model. (Address question 3.) You should provide enough detail such that someone else could implement your analysis."
  },
  {
    "objectID": "case_study/case_study_1_template.html#gibbs-sampler",
    "href": "case_study/case_study_1_template.html#gibbs-sampler",
    "title": "STAT 412: Case Study 1",
    "section": "Gibbs sampler",
    "text": "Gibbs sampler\n\n# code for your gibbs sampler should go here\n# remember to only keep necessary code for submission!"
  },
  {
    "objectID": "case_study/case_study_1_template.html#results",
    "href": "case_study/case_study_1_template.html#results",
    "title": "STAT 412: Case Study 1",
    "section": "Results",
    "text": "Results\n\nDiagnostics\nFirst do some diagnostics to see if your chain has converged\n\n\nFindings\nProvide results with interpretation (Address question 4). You should alternate between R code and text!"
  },
  {
    "objectID": "case_study/case_study_1_template.html#conclusion",
    "href": "case_study/case_study_1_template.html#conclusion",
    "title": "STAT 412: Case Study 1",
    "section": "Conclusion",
    "text": "Conclusion\nGive a conclusion that answers the research question (Address question 5)."
  },
  {
    "objectID": "handouts/jeffreys_prior_normal.html",
    "href": "handouts/jeffreys_prior_normal.html",
    "title": "Jeffreys Prior",
    "section": "",
    "text": "Suppose I use Jeffrey’s prior for \\(\\theta\\), but I don’t use Jeffrey’s prior for \\(\\gamma = e^{\\theta}\\). Then if I obtain the posterior for \\(\\theta\\) and transform that posterior to \\(\\gamma\\) space, I’m not guaranteed to get the same posterior as if I’d started in \\(\\gamma\\)-space to begin with!\n\nlibrary(pracma)\n\n# Data: single observation\ny &lt;- 2.5\nsigma &lt;- 1\n\n# Grid in mu-space\nmu_vec &lt;- seq(-5, 5, length.out = 10000)\n\n# Likelihood in mu\nlik_mu &lt;- dnorm(y, mean = mu_vec, sd = sigma)\n\n# Prior 1: Jeffreys prior on mu: uniform (constant)\nprior_jeff_mu &lt;- rep(1, length(mu_vec))\n\n# Posterior in mu under Jeffreys prior for mu\npost_mu_jeff &lt;- lik_mu * prior_jeff_mu\npost_mu_jeff &lt;- post_mu_jeff / trapz(mu_vec, post_mu_jeff)\n\n# Transform parameter: gamma = exp(mu)\ngamma_vec &lt;- exp(mu_vec)\ndmu_dgamma &lt;- 1 / gamma_vec  # derivative of mu w.r.t gamma\n\n# Transform posterior to gamma-space\npost_gamma_from_mu &lt;- post_mu_jeff / dmu_dgamma  # divide by |dmu/dgamma| for pdf transform\npost_gamma_from_mu &lt;- post_gamma_from_mu / trapz(gamma_vec, post_gamma_from_mu)\n\n# flat prior on gamma (this is NOT jeffrey's prior for gamma)\nprior_flat_gamma &lt;- rep(1, length(gamma_vec))\n\n# Likelihood in gamma-space (transform mu to gamma)\nlik_gamma &lt;- dnorm(y, mean = log(gamma_vec), sd = sigma)\n\n\n# Posterior in gamma-space under flat prior for gamma\npost_gamma &lt;- lik_gamma * prior_flat_gamma\npost_gamma &lt;- post_gamma / trapz(gamma_vec, post_gamma)\n\n# Sampling function from mu posterior\ncdf_mu_jeff &lt;- cumtrapz(mu_vec, post_mu_jeff)\ncdf_mu_jeff &lt;- cdf_mu_jeff / max(cdf_mu_jeff)\nsample_mu &lt;- function(n) {\n  u &lt;- runif(n)\n  approx(cdf_mu_jeff, mu_vec, xout = u, rule = 2)$y\n}\nmu_samps_jeff &lt;- sample_mu(50000)\n# induced gamma posterior from jeffrey's prior on mu\ngamma_samps_from_mu_jeff &lt;- exp(mu_samps_jeff)\n\n# Sampling function from gamma posterior\ncdf_gamma &lt;- cumtrapz(gamma_vec, post_gamma)\ncdf_gamma &lt;- cdf_gamma / max(cdf_gamma)\nsample_gamma &lt;- function(n) {\n  u &lt;- runif(n)\n  approx(cdf_gamma, gamma_vec, xout = u, rule = 2)$y\n}\n# gamma posterior with flat prior on gamma starting in gamma space\ngamma_samps &lt;- sample_gamma(50000)\n\n\n\n\n\n\n\n\n\n\nNow what happens if I use Jeffrey’s prior for \\(\\theta\\) and also Jeffrey’s prior for \\(\\gamma\\)? The posteriors in \\(\\gamma\\)-space ought to look the same!\n\n# Jeffreys prior on gamma is proportional to 1/gamma\nprior_jeff_gamma &lt;- 1 / gamma_vec\n\n# Posterior in gamma under jeffreys prior\npost_gamma_jeff &lt;- lik_gamma * prior_jeff_gamma\npost_gamma_jeff &lt;- post_gamma_jeff / trapz(gamma_vec, post_gamma_jeff)\n\n# Sampling functions using inverse CDF method\ncdf_gamma_jeff &lt;- cumtrapz(gamma_vec, post_gamma_jeff)\ncdf_gamma_jeff &lt;- cdf_gamma_jeff / max(cdf_gamma_jeff)\nsample_gamma_jeff &lt;- function(n) {\n  u &lt;- runif(n)\n  approx(cdf_gamma_jeff, gamma_vec, xout = u, rule = 2)$y\n}\n# gamma posterior with Jeffreys prior on gamma starting in gamma space\ngamma_samps_jeff &lt;- sample_gamma_jeff(50000)"
  },
  {
    "objectID": "code/hierarchical_normal_schools.html",
    "href": "code/hierarchical_normal_schools.html",
    "title": "Hierarchical modeling: Normal data",
    "section": "",
    "text": "We have data from the 2002 Educational Longitudinal Study (ELS), a survey of students from a large sample of schools across the United States. This dataset includes a population of schools as well as a population of students within each school. Note that this is a nested/hierarchical structure. This survey included 10th grade children from 100 diﬀerent large urban public high schools, all having a 10th grade enrollment of 400 or greater. Note that the number of students sampled from each school differs.\nIn particular, we have data from math scores from a math exam on the ELS, which was standardized to produce a nationwide mean of 50 and a standard deviation of 10.\nThe following displays boxplots of the distribution of math scores by school. The pink line displays the overall sample mean score, averaged across all schools and students. What do we notice?\n\n\n\n\n\n\n\n\n\nHere, we plot the distribution sample mean scores of each school (left), along with the sample mean scores as a function of the sample size from the school (right). What do we notice here?"
  },
  {
    "objectID": "code/hierarchical_normal_schools.html#data-and-eda",
    "href": "code/hierarchical_normal_schools.html#data-and-eda",
    "title": "Hierarchical modeling: Normal data",
    "section": "",
    "text": "We have data from the 2002 Educational Longitudinal Study (ELS), a survey of students from a large sample of schools across the United States. This dataset includes a population of schools as well as a population of students within each school. Note that this is a nested/hierarchical structure. This survey included 10th grade children from 100 diﬀerent large urban public high schools, all having a 10th grade enrollment of 400 or greater. Note that the number of students sampled from each school differs.\nIn particular, we have data from math scores from a math exam on the ELS, which was standardized to produce a nationwide mean of 50 and a standard deviation of 10.\nThe following displays boxplots of the distribution of math scores by school. The pink line displays the overall sample mean score, averaged across all schools and students. What do we notice?\n\n\n\n\n\n\n\n\n\nHere, we plot the distribution sample mean scores of each school (left), along with the sample mean scores as a function of the sample size from the school (right). What do we notice here?"
  },
  {
    "objectID": "code/hierarchical_normal_schools.html#prior-solitication",
    "href": "code/hierarchical_normal_schools.html#prior-solitication",
    "title": "Hierarchical modeling: Normal data",
    "section": "Prior solitication",
    "text": "Prior solitication\nSet priors based on the information provided by ELS: the math exam was designed to give a mean of 50 and a nationwide variance of 100. Note: this variance includes both within-school and between-school variance.\nLet’s brainstorm how to translate these into sensible prior parameter values for the unknown parameters! We need to put things in context. Recall:\n\\[\\theta \\sim N(\\mu_{0}, \\sigma^{2}_{0})\\] \\[1/\\sigma^2 \\sim \\text{Gamma}(a, b)\\] \\[1/\\tau^2 \\sim \\text{Gamma}(c, d)\\]"
  },
  {
    "objectID": "code/hierarchical_normal_schools.html#some-mcmc-diagnostics",
    "href": "code/hierarchical_normal_schools.html#some-mcmc-diagnostics",
    "title": "Hierarchical modeling: Normal data",
    "section": "Some MCMC diagnostics",
    "text": "Some MCMC diagnostics\nRan chain with burn-in of 5000 and then retained 5000 samples. The following plots are another way to determine stationarity/convergence. We can produce boxplots of sequential groups of MCMC samples. In the following, each of the 10 boxplots represents 1/10th of the MCMC samples. If convergence has been achieved, then the distribution of samples in any one boxplot should be the same as that in any other (for a given parameter).\n\n\n\n\n\n\n\n\n\nShowing a subset of the \\(\\theta_{j}\\) (first 9 schools) for illustrative purposes:\n\n\n\n\n\n\n\n\n\nEffective sample sizes from 5000 iterations post burn-in for \\(\\theta\\), \\(\\sigma^2\\), \\(\\tau^2\\) are: 3733.74, 4849.7, 2734.02. The ESS for the \\(\\theta_{j}\\) chains range from 4119.69 to 5526.92."
  },
  {
    "objectID": "code/hierarchical_normal_schools.html#posterior-inference",
    "href": "code/hierarchical_normal_schools.html#posterior-inference",
    "title": "Hierarchical modeling: Normal data",
    "section": "Posterior inference",
    "text": "Posterior inference\nPosterior means and 95% credible intervals of \\(\\theta\\), \\(\\sigma\\), and \\(\\tau\\) are as follows. Let’s think about their interpretation.\n\n\n\n\n\nThe following displays the posterior distributions of the school-specific mean scores \\(\\theta_{j}\\), in order of smallest to largest:\n\n\n\n\n\n\n\n\n\nThis plot illustrates the notion of “shrinkage” or “borrowing information”. Let’s interpret!"
  },
  {
    "objectID": "homework/412_hw5_r_starter.html#part-a",
    "href": "homework/412_hw5_r_starter.html#part-a",
    "title": "STAT 412: Homework 5 (R)",
    "section": "Part a",
    "text": "Part a\n\n# specifying priors"
  },
  {
    "objectID": "homework/412_hw5_r_starter.html#part-b",
    "href": "homework/412_hw5_r_starter.html#part-b",
    "title": "STAT 412: Homework 5 (R)",
    "section": "Part b",
    "text": "Part b\n\n# gibbs sampler here"
  },
  {
    "objectID": "homework/412_hw5_r_starter.html#part-c",
    "href": "homework/412_hw5_r_starter.html#part-c",
    "title": "STAT 412: Homework 5 (R)",
    "section": "Part c",
    "text": "Part c"
  },
  {
    "objectID": "homework/412_hw5_r_starter.html#part-d",
    "href": "homework/412_hw5_r_starter.html#part-d",
    "title": "STAT 412: Homework 5 (R)",
    "section": "Part d",
    "text": "Part d"
  },
  {
    "objectID": "homework/412_hw5_r_starter.html#part-e",
    "href": "homework/412_hw5_r_starter.html#part-e",
    "title": "STAT 412: Homework 5 (R)",
    "section": "Part e",
    "text": "Part e"
  },
  {
    "objectID": "homework/412_hw5_r_starter.html#part-f",
    "href": "homework/412_hw5_r_starter.html#part-f",
    "title": "STAT 412: Homework 5 (R)",
    "section": "Part f",
    "text": "Part f"
  },
  {
    "objectID": "homework/412_hw5_r_starter.html#part-b-1",
    "href": "homework/412_hw5_r_starter.html#part-b-1",
    "title": "STAT 412: Homework 5 (R)",
    "section": "Part b",
    "text": "Part b\n\n# model 1 PPC"
  },
  {
    "objectID": "homework/412_hw5_r_starter.html#part-e-1",
    "href": "homework/412_hw5_r_starter.html#part-e-1",
    "title": "STAT 412: Homework 5 (R)",
    "section": "Part e",
    "text": "Part e\n\n# model 2 Gibbs"
  },
  {
    "objectID": "homework/412_hw5_r_starter.html#part-f-1",
    "href": "homework/412_hw5_r_starter.html#part-f-1",
    "title": "STAT 412: Homework 5 (R)",
    "section": "Part f",
    "text": "Part f\n\n# model 2 posterior summary"
  },
  {
    "objectID": "homework/412_hw5_r_starter.html#part-g",
    "href": "homework/412_hw5_r_starter.html#part-g",
    "title": "STAT 412: Homework 5 (R)",
    "section": "Part g",
    "text": "Part g\n\n# model 2 posterior summary"
  },
  {
    "objectID": "homework/412_hw5_r_starter.html#part-e-optional",
    "href": "homework/412_hw5_r_starter.html#part-e-optional",
    "title": "STAT 412: Homework 5 (R)",
    "section": "Part e (optional)",
    "text": "Part e (optional)"
  },
  {
    "objectID": "code/bayes_slr.html",
    "href": "code/bayes_slr.html",
    "title": "Bayes Simple Linear Regression",
    "section": "",
    "text": "We have data that contains teacher salaries from 2009-2010 for teachers employed by the St. Louis Public School in Michigan. The dataset has been filtered to retain only teachers with at most 15 years of service and who have a full teaching load (FTE). This leaves in total 39 teachers. I have modified the data slightly to make this analysis more interesting.\nWe have the following variables:\n\nid: Identification code for each teacher, assigned randomly\ndegree: Highest educational degree attained: BA (bachelor’s degree) or MA (master’s degree)\nyears: Number of years employed by the school district\nbase: Base annual salary, in dollars.\n\nWe have the following snapshot of the data:\n\n\n\n\n\nid\ndegree\nfte\nyears\nbase\n\n\n\n\n01\nBA\n1\n5\n45231.39\n\n\n02\nMA\n1\n15\n60694.91\n\n\n04\nBA\n1\n10\n54257.09\n\n\n07\nBA\n1\n12\n58495.82\n\n\n11\nBA\n1\n12\n58179.38\n\n\n\n\n\nSuppose I’m a teacher who is moving to Michigan, and I’m interested in learning what kind of salary I could expect to earn. I know that salaries are related in some way to years of experience, so let’s do some EDA to see the empirical relationship between years of experience and base salary at this public school:\n\n\n\n\n\n\n\n\n\nWhat do we notice?"
  },
  {
    "objectID": "code/bayes_slr.html#data-and-eda",
    "href": "code/bayes_slr.html#data-and-eda",
    "title": "Bayes Simple Linear Regression",
    "section": "",
    "text": "We have data that contains teacher salaries from 2009-2010 for teachers employed by the St. Louis Public School in Michigan. The dataset has been filtered to retain only teachers with at most 15 years of service and who have a full teaching load (FTE). This leaves in total 39 teachers. I have modified the data slightly to make this analysis more interesting.\nWe have the following variables:\n\nid: Identification code for each teacher, assigned randomly\ndegree: Highest educational degree attained: BA (bachelor’s degree) or MA (master’s degree)\nyears: Number of years employed by the school district\nbase: Base annual salary, in dollars.\n\nWe have the following snapshot of the data:\n\n\n\n\n\nid\ndegree\nfte\nyears\nbase\n\n\n\n\n01\nBA\n1\n5\n45231.39\n\n\n02\nMA\n1\n15\n60694.91\n\n\n04\nBA\n1\n10\n54257.09\n\n\n07\nBA\n1\n12\n58495.82\n\n\n11\nBA\n1\n12\n58179.38\n\n\n\n\n\nSuppose I’m a teacher who is moving to Michigan, and I’m interested in learning what kind of salary I could expect to earn. I know that salaries are related in some way to years of experience, so let’s do some EDA to see the empirical relationship between years of experience and base salary at this public school:\n\n\n\n\n\n\n\n\n\nWhat do we notice?"
  },
  {
    "objectID": "code/bayes_slr.html#fitting-a-slr",
    "href": "code/bayes_slr.html#fitting-a-slr",
    "title": "Bayes Simple Linear Regression",
    "section": "Fitting a SLR",
    "text": "Fitting a SLR\nI will fit a SLR model to these data, regressing base salary on years of experience (ignoring degree for now). Thus, in context, my SLR looks like the following:\n\\[\\text{base}_{i} = \\beta_{0} + \\beta_{1} \\text{years}_{i} + \\epsilon_{i}\n\\] \\[\\epsilon_{i} \\overset{iid}{\\sim} N(0, \\sigma^2) \\qquad \\quad i = 1,\\ldots, n = `r nrow(teachers)\\]\n\nPrior solicitation 1\nMy priors might be specified as follows:\n\\[\\beta_{0} \\sim N(0, 100^2)\\] \\[\\beta_{1} \\sim N(0, 100^2)\\] \\[\\frac{1}{\\sigma^2} \\sim \\text{Gamma}(1,1)\\]\nWhat’s possibly wrong with this prior specification??\n\n\nPrior solicitation 2\nLet’s choose the following new priors:\n\\[\\beta_{0} \\sim N(50000, 10000^2)\\] \\[\\beta_{1} \\sim N(0, 10000^2)\\]\nTo approximate the joint posterior distribution, I will run a Gibbs sampler for 20000 iterations, throwing the first half away to burn-in.\n\n\nDiagnostics\nHere are some traceplots:\n\n\n\n\n\n\n\n\n\nThe effective sample sizes of \\(\\beta_{0}, \\beta_{1}, \\sigma^2\\) from these 10000 iterations are: 1340.28, 1291.16, 8044.04. Why do we think some of these are so low?"
  },
  {
    "objectID": "code/bayes_slr.html#model-assessment",
    "href": "code/bayes_slr.html#model-assessment",
    "title": "Bayes Simple Linear Regression",
    "section": "Model assessment",
    "text": "Model assessment\n\nPosterior predictive check\nTo assess the fit of a SLR model, one approach is to generate PPDs and compare them (visually) to the original data. Once again, we want the observed response values to be consistent with predicted responses generated from the fitted model. So, as before, let’s generate some PPDs. For \\(k \\in 1:K\\):\n\nObtain/sample posterior values of \\(\\beta_{0}, \\beta_{1}, \\sigma_{2}\\), call these \\(\\beta^*_{0}, \\beta^{*}_{1}, \\sigma^{2*}\\).\nSample \\(\\mathbf{y}^{*} = \\{y^{*}_{1},\\ldots,y_{n}^{*} \\}\\) where \\(n\\) is the sample size \\(n= 39\\) and \\(y_{i}^{*} \\sim N(\\beta^*_{0}+ \\beta^{*}_{1} x_{i}, \\sigma^{2*})\\). Note that these \\(x_{i}\\) are the same as in the original data, as they are assumed fixed!\n\n\nset.seed(1)\nK &lt;- 8\nsamp_ids &lt;- sample(1:G, K) # G is number of iterations post burn-in\nppd_ls &lt;- list() \n# POSTS is matrix with columns [beta0, beta1, s2]\n# y is vector of base salary, x is vector of years of experience\nfor (k in 1:K){\n  ppd_y &lt;- rnorm(n, POSTS[samp_ids[k],1] + POSTS[samp_ids[k],2] * x,\n               sqrt(POSTS[samp_ids[k],3]))\n  ppd_ls[[k]] &lt;- data.frame(base = ppd_y,\n                   years = x, \n                   dist = paste0(\"PPD\", k)) # variable for plotting\n}\n# append on original/true y\nppd_ls[[k+1]] &lt;- data.frame(base = y, years = x, dist = \"Original\")\n\ndo.call(rbind, ppd_ls) |&gt;\n  ggplot(aes(x = years, y = base)) +\n  geom_point() +\n  facet_wrap(~ dist)\n\n\n\n\n\n\n\n\nWhat do we notice?\n\n\nResiduals\nWhen fitting a linear regression model, a very common way of assessing model fit is to look at the residuals: \\(e_{i} = y_{i} - \\hat{y}_{i}\\) where \\(\\hat{y}_{i}\\) is the fitted/estimated value of the \\(i\\)-th response. We should ideally have residuals close to 0. Additionally, residuals shouldn’t “look” very different from different values of \\(x_{i}\\) (i.e. we don’t want to do better at predicting certain observations than others).\nTo do this, as before, for some number \\(K\\) times:\n\nObtain/sample parameter values from the posterior\nSimulate \\(y_{i}^*\\) from its corresponding Normal distribution using the posterior values from 1.\nObtain \\(e_{i} = y_{i} - y_{i}^*\\)\n\nBecause the predicted values are random, so are the residuals \\(e_{i}\\). So, our residual plot will look different from the usual, frequentist residual plot. We can plot credible intervals of the residuals for each observation \\(i\\)! Thus, in this diagnostic, we should choose \\(K\\) large (e.g. the total number of iterations after burn-in) so to get good approximations of the variablity.\n\nset.seed(1)\nresids_ls &lt;- list()\nfor(i in 1:n){\n  y_preds_i &lt;- rnorm(G, POSTS[,1] + POSTS[,2] * x[i], sqrt(POSTS[,3]))\n  resids &lt;- y[i] - y_preds_i\n  resids_ls[[i]] &lt;- data.frame(resid = resids, obs = i, years = x[i])\n}\nresids_df_all &lt;- do.call(rbind, resids_ls)\n\nSnapshot of resids_df_all:\n\n\n\n\n\nresid\nobs\nyears\n\n\n\n\n-254.1278\n1\n5\n\n\n-1330.9272\n1\n5\n\n\n1347.9132\n1\n5\n\n\n\n\n\n\\[\\vdots\\]\n\n\n\n\n\nresid\nobs\nyears\n\n\n\n\n2007.4218\n39\n5.5\n\n\n731.1135\n39\n5.5\n\n\n4374.1961\n39\n5.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat do we notice here?"
  },
  {
    "objectID": "code/bayes_slr.html#posterior-inference",
    "href": "code/bayes_slr.html#posterior-inference",
    "title": "Bayes Simple Linear Regression",
    "section": "Posterior inference",
    "text": "Posterior inference\nRegardless of what we determined above about model fit, let’s continue with doing some posterior inference.\n\nPosterior summaries\nHere are some posterior summaries of the three parameters:\n\n\n\n\n\nLet’s give some interpretation!\n\n\nLine of best fit\nLet’s obtain a line of “best fit” (note that a is italicized because there is not a notion of a single best line). One might obtain such a line by taking the posterior mean estimates \\((\\hat{\\beta}_{0}, \\hat{\\beta}_{1})\\) of \\((\\beta_{0}, \\beta_{1})\\), and use them to plot the line \\(\\hat{y} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1} x\\).\nIf we use the posterior means as the estimates, then this “best line” represents the most likely value of the line \\(\\beta_{0} + \\beta_{1} x\\) from the posterior distribution. To include some notion of uncertainty of this “best line”, we might also plot some number of \\(J\\) line estimates where we take samples \\((\\beta_{0}^{(j)}, \\beta_{1}^{(j)})\\) from the posterior (i.e. Gibbs sampler) and plot \\(\\beta_{0}^{(j)} + \\beta_{1}^{(j)} x\\).\n\nset.seed(1)\nJ &lt;- 10\niter_samps &lt;- sample(1:G, J) \npost_means &lt;- colMeans(POSTS)\n\nggplot(teachers, aes(x = years, y = base)) +\n  geom_point(size=2) +\n  geom_abline(data=post_df[iter_samps, ], aes(intercept=beta0, slope=beta1),\n              alpha = 0.2, col = \"magenta\") +\n  geom_abline(intercept = post_means[1],\n              slope = post_means[2], col = \"blue\") +\n  ylab(\"Base salary ($)\") + xlab(\"Years\") +\n  labs(caption = \"Blue line: a line of best fit \\n Pink lines: posterior samples of line\")\n\n\n\n\n\n\n\n\nWhat do we notice?\n\n\nPredicted responses\nI have approximately 3.5 years of teaching experience and my friend has approximately 8.5 years. I might like to know what sort of ranges of base salaries we might expect to earn. To answer this question, why not obtain the posterior density of base salaries for each of \\(x^{(new)} = 3.5\\) and \\(x^{(new)} = 8.5\\)? Do the following for \\(k = 1,\\ldots K\\) (once again, with \\(K\\) large):\n\nUse the posterior samples of \\(\\beta_{0}, \\beta_{1}\\) to simulate the expected earnings at a given level \\(x^{(new)}\\) of years of experience\nRandomly sample the earnings at this mean using the Normal model and a posterior sample of \\(\\sigma^2\\)"
  },
  {
    "objectID": "code/bayes_mlr.html",
    "href": "code/bayes_mlr.html",
    "title": "Bayesian Multiple Linear Regression",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = F, message = F, warning = F, fig.width = 5, fig.height = 3)\nlibrary(mvtnorm) # install if necessary\nlibrary(tidyverse)\nlibrary(kableExtra)\nData from \\(n = 113\\) hospitals are used to assess what factors may influence the likelihood that a patient acquires an infection while hospitalized. We have the following variables:\nInfctRsk\nStay\nXray\n\n\n\n\n4.1\n7.13\n39.6\n\n\n1.6\n8.82\n51.7\n\n\n2.7\n8.34\n74.0\n\n\n5.6\n8.95\n122.8\nPerhaps we’d like to understand how the infection risk is related to the length of stay and number of x-rays given in a hospital, so we fit the following regression model: \\[\\text{InfctRisk}_{i} = \\beta_{0} + \\beta_{1} \\text{Stay}_{i} + \\beta_{2} \\text{Xray}_{i} + \\epsilon_{i}, \\qquad i = 1,\\ldots,n\\] where the \\(\\epsilon_{i} \\overset{iid}{\\sim} N(0,\\sigma^2)\\) are iid.\nLetting \\(Y_{i} = \\text{InfctRisk}_{i}\\), \\(\\mathbf{x}_{i} = (1, \\text{Stay}_{i}, \\text{Xray}_{i})'\\), and \\(\\boldsymbol{\\beta} = (\\beta_{0}, \\beta_{1}, \\beta_{2})'\\) we have the following sampling model:\n\\[\ny_{i}|\\mathbf{x}_{i}, \\boldsymbol{\\beta}, \\sigma^2 \\sim N(\\mathbf{x}_{i}' \\boldsymbol{\\beta}, \\sigma^2), \\qquad i = 1,\\ldots, n\n\\]"
  },
  {
    "objectID": "code/bayes_mlr.html#prior-option-1",
    "href": "code/bayes_mlr.html#prior-option-1",
    "title": "Bayesian Multiple Linear Regression",
    "section": "Prior option 1",
    "text": "Prior option 1\nwe might choose the following (independent) priors:\n\\[\\boldsymbol{\\beta} \\sim MVN_{3}(\\boldsymbol{\\mu}_{0}, \\boldsymbol{\\Sigma}_{0})\\] \\[\\frac{1}{\\sigma^2} \\sim \\text{Gamma}(1,1)\\]\nAnd in particular, we might choose \\(\\boldsymbol{\\mu}_{0} = (0,0,0)'\\) (the scale of the \\(Y_{i}\\) are small, and a priori assume no relationship). We might also assume \\(\\Sigma_{0} = 100^2 \\mathbf{I}_{3}\\) (i.e. the coefficients are independent and have a s.d. of 100).\nWe can approximate the posteriors of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) using a Gibbs sampler.\n\nData set-up\nWe need to do just a small amount of work to specify the data matrix \\(\\mathbf{X}\\), where each row corresponds to each observation \\(i\\)’s predictors, and we have a column of 1’s for the intercept:\n\n\n     [,1]  [,2]  [,3]\n[1,]    1  7.13  39.6\n[2,]    1  8.82  51.7\n[3,]    1  8.34  74.0\n[4,]    1  8.95 122.8\n[5,]    1 11.20  88.9\n[6,]    1  9.76  97.0\n\n\n  (Intercept)  Stay  Xray\n1           1  7.13  39.6\n2           1  8.82  51.7\n3           1  8.34  74.0\n4           1  8.95 122.8\n5           1 11.20  88.9\n6           1  9.76  97.0\n\n\nThen we set-up the rest of the necessary data components:\n\n\nRunning Gibbs sampler\nCheck traceplots to assess convergence:\n\n\n\n\n\n\n\n\n\nLook at effective sample size from \\(G = r G/2\\) iterations:\n\nlibrary(coda)\napply(BETAS, 2, effectiveSize)\n\n[1] 5000 5000 5000\n\neffectiveSize(S2)\n\nvar1 \n5000 \n\n\nHow does this compare to ESS from SLR? Why do we think that is?\nCheck sample lag-2 autocorrelation:\n\n\n          lag-0        lag-1        lag-2\nIntercept     1 -0.014393436  0.012124642\nstay          1 -0.009353404  0.004008842\nxray          1 -0.008098636  0.025658893\ns2            1  0.009352675 -0.023047790\n\n\n\n\nPosterior inference"
  },
  {
    "objectID": "code/metropolis.html",
    "href": "code/metropolis.html",
    "title": "Metropolis example",
    "section": "",
    "text": "Maybe I’m thinking about moving to Burlington and I’d like to know the average amount of snowfall \\(\\theta\\) I should expect in a given year. Luckily, there is some historic data about the observed total snowfall in Burlington from each winter season since 20004, courtesy of NOAA. Before taking a look at the data, we should formulate a prior. Let me first graph the data for you (hiding the values themselves):"
  },
  {
    "objectID": "code/metropolis.html#data",
    "href": "code/metropolis.html#data",
    "title": "Metropolis example",
    "section": "",
    "text": "Maybe I’m thinking about moving to Burlington and I’d like to know the average amount of snowfall \\(\\theta\\) I should expect in a given year. Luckily, there is some historic data about the observed total snowfall in Burlington from each winter season since 20004, courtesy of NOAA. Before taking a look at the data, we should formulate a prior. Let me first graph the data for you (hiding the values themselves):"
  },
  {
    "objectID": "code/metropolis.html#model-1",
    "href": "code/metropolis.html#model-1",
    "title": "Metropolis example",
    "section": "Model 1",
    "text": "Model 1\nThis looks like maybe we could model the yearly snowfall as Normal with unknown mean \\(\\theta\\). For now, let’s assume that \\(\\sigma^2\\) is equal to the observed sample variance \\(s^2\\) for simplicity (i.e. \\(\\sigma^2\\) = 554.885).\nThen a model that we’ve used before could be the Normal-Normal model:\n\\[Y_{i} | \\theta \\overset{iid}{\\sim} N(\\theta, 554.885) \\qquad i = 1,\\ldots, n = 20\n\\] \\[\\theta \\sim N(\\mu_{0}, \\sigma_{0}^2)\\] For my prior probability, I might think that on average, Burlington gets 10 feet = 120 inches of snow in a winter season, with a standard deviation of 1 foot = 12 inches. So \\(\\mu_{0} = 120\\) and \\(\\sigma_0^2 = 144\\). We could obtain Monte Carlo amples for \\(\\theta\\) from its posterior directly, but let’s jump ahead to obtain some PPDs to see if this model is a good fit. I’ll simulate 50 PPDs, and graph them alongside the observed data. Additionally, I’ll calculate the test function \\(T(\\mathbf{y^*}) = \\frac{1}{n} \\sum y_{i}^*\\) (i.e. the sample mean) for each PPD and compare them to the observed \\(\\bar{y}\\).\n\n\n\n\n\n\n\n\n\nWhat do we think about this model?"
  },
  {
    "objectID": "code/metropolis.html#model-2",
    "href": "code/metropolis.html#model-2",
    "title": "Metropolis example",
    "section": "Model 2",
    "text": "Model 2\nLet’s consider the same sampling distribution model, but a different prior for \\(\\theta\\). Maybe I’d like a prior for \\(\\theta\\) that has thicker/heavier tails than a Normal distribution (i.e. has more prior probability for extreme values than the Normal). This could be useful since I actually don’t know what the average snowfall is, and my original prior could be way off.\nLet’s consider the Cauchy distribution as a prior for \\(\\theta\\) (a truly terrible distribution). The Cauchy distribution is parameterized by a location parameter \\(\\theta_{0} \\in \\mathbb{R}\\) and a scale parameter \\(\\kappa &gt;0\\). If \\(X \\sim \\text{Cauchy}(\\mu_{0},\\kappa)\\) then its pdf is\n\\[f(x | \\mu_0, \\kappa) = \\frac{1}{\\pi \\kappa \\left( 1 + \\left(\\frac{x - \\mu_{0}}{\\kappa} \\right)^2 \\right)}, \\qquad x \\in \\mathbb{R}\\]\nWeirdly, the Cauchy doesn’t have a finite mean.\nFor this Model 2, I will use the following prior for \\(\\theta\\):\n\\[\\theta \\sim \\text{Cauchy}(120, 6)\\] Then this has similar prior beliefs as under the Normal above: this Cauchy is roughly centered at 10 feet of snow and has 70% prior probability of being between 9 and 11 feet:\n\nqcauchy(0.15, 120, 6)/12 # convert to feet\n\n[1] 9.018695\n\nqcauchy(0.85, 120, 6)/12 \n\n[1] 10.98131\n\n\nHere, we can see the difference between the Normal prior from Model 1 and the new Cauchy prior from this new Model 2:\n\n\n\n\n\n\n\n\n\nUnfortunately, the Cauchy is not a conjugate prior for the Normal sampling model. Rather than try to derive the posterior exactly, let’s instead use the Metropolis algorithm to approximate the posterior for \\(\\theta\\)!\n\nset.seed(412)\nsnow &lt;- read_csv(\"../handouts/burlington_snow.csv\")\ny &lt;- snow$snowfall\nn &lt;- length(y)\ns2 &lt;- var(y)\nybar &lt;- mean(y)\nloc0 &lt;- 10*12\nscale0 &lt;- 12*(0.5)\nS &lt;- 5000\nTHETA &lt;- rep(NA, S)\n\n# keep track of how many times we accept\naccept_vec &lt;- rep(0, S)\ndelta &lt;- 1 # a proposal of 1 inch \n# initialize \ntheta &lt;- loc0\nfor(s in 1:S){\n  # step 1: propose\n  theta_prop &lt;- rnorm(1, theta, delta) \n  \n  # step 2: calculate acceptance ratio (demonstrate why we log instead of prod)\n  log_r &lt;- sum(dnorm(y, theta_prop, sqrt(s2), log = T)) -\n    sum(dnorm(y, theta, sqrt(s2), log = T)) +\n    dcauchy(theta_prop, loc0, scale0, log = T) -\n    dcauchy(theta, loc0, scale0, log = T)\n  \n  # step 3: decide\n  u &lt;- runif(1)\n  if(log(u) &lt; log_r){ # remember: r is on log scale\n    theta &lt;- theta_prop\n    accept_vec[s] &lt;- 1 \n  } \n  # else: keep theta where it currently is\n  \n  ## STORE like usual\n  THETA[s] &lt;- theta\n}\n\n# burn\nTHETA &lt;- THETA[-c(1:(S/2))]\n\nLet’s examine the traceplot for the chain after burn-in:\n\n\n\n\n\n\n\n\n\nThis looks bad! Why is that? Let’s also examine the proportion of times we accepted the proposal in our sampler:\n\nmean(accept_vec)\n\n[1] 0.9446\n\n\nThis is a very high acceptance probability! This means that about 95% of the time, we are accepting the proposed \\(\\theta^{(prop)}\\). This means that the \\(\\delta\\) we chose is too small; all proposed values are very similar to the “current” \\(\\theta\\) and are thus getting accepted. This leads to high autocorrelation and stickiness in our chain, and thus the bad-looking traceplots. So we should increase \\(\\delta\\)! Let’s try increasing \\(\\delta\\) to see what happens. There is literature that suggests an ideal acceptance ratio for Metropolis is 0.234. Let’s try to get close to that:\n\n\n\n\n\n\n\n\n\nThis traceplot with \\(\\delta =\\) 20 looks much better. The acceptance ratio now is 0.3166, which is much closer to “ideal”.\nNow we can do posterior inference with \\(\\theta\\) as we usually would! Let’s now do some a PPCs to compare Model 2 to Model 1. I will do the same before: obtain 50 PPDs and calculate the test function."
  },
  {
    "objectID": "code/metropolis.html#appendix",
    "href": "code/metropolis.html#appendix",
    "title": "Metropolis example",
    "section": "Appendix",
    "text": "Appendix\nNote that we might that we are “lucky” that R provides the density functions dnorm() and dcauchy() for us. But we actually don’t need that! As long as we have closed-form expressions for the likelihood and prior (up to proportionality), we can calculate the acceptance ratio:\n\n# set for demonstration\ntheta &lt;- 100\ntheta_prop &lt;- 102\n\n# using R's functions\nsum(dnorm(y, theta_prop, sqrt(s2), log = T)) -\n    sum(dnorm(y, theta, sqrt(s2), log = T)) +\n    dcauchy(theta_prop, loc0, scale0, log = T) -\n    dcauchy(theta, loc0, scale0, log = T)\n\n[1] -1.157209\n\n\nIn the following, we leverage that when we take log densities, things cancel out:\n\\[\\log f(\\mathbf{y} | \\theta) = -\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n}(y_i - \\theta)^2 \\Rightarrow\\] \\[\\log f(\\mathbf{y} | \\theta^{(prop)}) - \\log f(\\mathbf{y} | \\theta^{(s)}) = -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n}(y_i - \\theta^{(prop)})^2- \\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n}(y_i - \\theta^{(s)})^2 \\right) \\] Similarly\n\\[\\log f(\\theta) = \\log \\left(\\frac{1}{\\pi \\kappa \\left( 1 + \\left(\\frac{\\theta - \\mu_{0}}{\\kappa} \\right)^2 \\right)}\\right) = -\\left( \\log(\\pi k) + \\log \\left( 1 + \\left(\\frac{\\theta - \\mu_{0}}{\\kappa} \\right)^2 \\right) \\right) \\Rightarrow\\]\n\\[\\log f(\\theta^{(prop)}) - \\log f(\\theta^{(s)}) = -\\log \\left( 1 + \\left(\\frac{\\theta^{(prop)} - \\mu_{0}}{\\kappa} \\right)^2 \\right)- \\left( \\log \\left( 1 + \\left(\\frac{\\theta^{(s)} - \\mu_{0}}{\\kappa} \\right)^2 \\right)\\right) \\]\n\n\n[1] -1.157209\n\n\nNotice that we get the same acceptance ratio!"
  },
  {
    "objectID": "code/metropolis.html#remark-on-coding-acceptance-ratio",
    "href": "code/metropolis.html#remark-on-coding-acceptance-ratio",
    "title": "Metropolis example",
    "section": "Remark on coding acceptance ratio",
    "text": "Remark on coding acceptance ratio\nNote that we might that we are “lucky” that R provides the density functions dnorm() and dcauchy() for us. But we actually don’t need that! As long as we have closed-form expressions for the likelihood and prior (up to proportionality), we can calculate the acceptance ratio:\n\n# set for demonstration\ntheta &lt;- 100\ntheta_prop &lt;- 102\n\n# using R's functions\nsum(dnorm(y, theta_prop, sqrt(s2), log = T)) -\n    sum(dnorm(y, theta, sqrt(s2), log = T)) +\n    dcauchy(theta_prop, loc0, scale0, log = T) -\n    dcauchy(theta, loc0, scale0, log = T)\n\n[1] -1.157209\n\n\nIn the following, we leverage that when we take log densities, things cancel out:\n\\[\\log f(\\mathbf{y} | \\theta) = -\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n}(y_i - \\theta)^2 \\Rightarrow\\] \\[\\log f(\\mathbf{y} | \\theta^{(prop)}) - \\log f(\\mathbf{y} | \\theta^{(s)}) = -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n}(y_i - \\theta^{(prop)})^2- \\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n}(y_i - \\theta^{(s)})^2 \\right) \\] Similarly\n\\[\\log f(\\theta) = \\log \\left(\\frac{1}{\\pi \\kappa \\left( 1 + \\left(\\frac{\\theta - \\mu_{0}}{\\kappa} \\right)^2 \\right)}\\right) = -\\left( \\log(\\pi k) + \\log \\left( 1 + \\left(\\frac{\\theta - \\mu_{0}}{\\kappa} \\right)^2 \\right) \\right) \\Rightarrow\\]\n\\[\\log f(\\theta^{(prop)}) - \\log f(\\theta^{(s)}) = -\\log \\left( 1 + \\left(\\frac{\\theta^{(prop)} - \\mu_{0}}{\\kappa} \\right)^2 \\right)- \\left( \\log \\left( 1 + \\left(\\frac{\\theta^{(s)} - \\mu_{0}}{\\kappa} \\right)^2 \\right)\\right) \\]\n\n# typing out the densities ourselves (up to proportionality)\n(-0.5)/s2 * sum((y - theta_prop)^2) - # log likelihood under theta_prop\n  (-0.5)/s2 * sum((y - theta)^2) + # log likelihood under current theta\n  - log(1 + ((theta_prop - loc0)/scale0)^2) - # log prior at theta_prop\n  - log(1 + ((theta- loc0)/scale0)^2) # log prior at current theta\n\n[1] -1.157209\n\n\nNotice that we get the same acceptance ratio!\nThis is especially useful when the likelihood is not one already provided by R."
  },
  {
    "objectID": "case_study/federalist_papers.html",
    "href": "case_study/federalist_papers.html",
    "title": "Untitled",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nfederalist &lt;- ProbBayes::federalist_word_study |&gt;\n  rename(\"Article\" = \"Name\") |&gt;\n  select(Article, Total, word, N, Authorship, Disputed) |&gt;\n  mutate(Authorship = as.character(Authorship)) |&gt;\n  mutate(Authorship = ifelse(Authorship == \"\", \"Jay\", Authorship),\n         word = as.character(word),\n         Disputed = as.character(Disputed),\n         Article = as.character(Article))\nham_df &lt;- federalist |&gt;\n  filter(word == \"an\") |&gt;\n  filter(Authorship == \"Hamilton\", Disputed == \"no\")\nmad_df &lt;- federalist |&gt;\n  filter(word == \"an\") |&gt;\n  filter(Authorship == \"Madison\", Disputed == \"no\")\n\nn1_vec &lt;- ham_df$Total\nn2_vec &lt;- mad_df$Total\ny1_vec &lt;- ham_df$N\ny2_vec &lt;- mad_df$N\n\nG &lt;- 10000\na_alpha &lt;- 0.001\nb_alpha &lt;- 0.001\n\na_beta &lt;- 0.001\nb_beta &lt;- 0.001\n\n\n\nfed_metropolis &lt;- function(y_vec, n_vec, G, a_alpha, b_alpha, a_beta, b_beta, alpha_sd, beta_sd){\n  alpha &lt;- a_alpha/b_alpha; \n  beta &lt;- a_beta/b_beta; \n  p_vec &lt;- beta / (beta+n_vec/1000)\n  alpha_acc &lt;- beta_acc &lt;- rep(0, G)\n  ALPHA &lt;- BETA &lt;- rep(NA, G)\n  for(g in 1:G){\n    log_alpha_prop &lt;- rnorm(1, log(alpha), alpha_sd)\n    alpha_prop &lt;- exp(log_alpha_prop)\n    r &lt;- sum(dnbinom(y_vec, alpha_prop, p_vec, log = T)) -\n    sum(dnbinom(y_vec, alpha, p_vec, log = T)) +\n    dgamma(alpha_prop, a_alpha, b_alpha, log = T) -\n    dgamma(alpha, a_alpha, b_beta, log = T) +\n      log_alpha_prop - log(alpha) # jacobian\n    if(log(runif(1)) &lt; r){\n      alpha &lt;- alpha_prop\n      alpha_acc[g] &lt;- 1\n    }\n    \n  \n    log_beta_prop &lt;- rnorm(1, log(beta), beta_sd)\n    beta_prop &lt;- exp(log_beta_prop)\n    p_prop_vec &lt;- beta_prop/(beta_prop + n_vec/1000)\n    r &lt;- sum(dnbinom(y_vec, alpha, p_prop_vec, log = T)) -\n      sum(dnbinom(y_vec, alpha, p_vec, log = T)) +\n      dgamma(beta_prop, a_beta, b_beta, log = T) -\n      dgamma(beta, a_beta, b_beta, log = T) +\n      log_beta_prop - log(beta) # jacobian\n    if(log(runif(1)) &lt; r){\n      beta &lt;- beta_prop\n      beta_acc[g] &lt;- 1\n      p_vec &lt;- p_prop_vec\n    }\n    \n  \n    \n    ALPHA[g] &lt;- alpha\n    BETA[g] &lt;- beta\n  }\n  \n  ALPHA &lt;- ALPHA[(G-5000):G]\n  BETA &lt;- BETA[(G-5000):G]\n  return(list(ALPHA = ALPHA, BETA = BETA, MU = ALPHA/BETA, accept_vec = c(mean(alpha_acc), mean(beta_acc))))\n}\n\n\n\n\nalpha_sd &lt;- 1\nbeta_sd &lt;- 0.5\nret_ham &lt;- fed_metropolis(y1_vec, n1_vec, G, a_alpha, b_alpha, a_beta, b_beta, alpha_sd = 0.2, beta_sd = 0.2)\nret_ham$accept_vec\n\n[1] 0.2961 0.2992\n\nret_mad &lt;- fed_metropolis(y2_vec, n2_vec, G, a_alpha, b_alpha, a_beta, b_beta, alpha_sd = .5, beta_sd = 0.5)\nret_mad$accept_vec\n\n[1] 0.1984 0.1931\n\nplot(ret_ham$MU, type = \"l\")\n\n\n\n\n\n\n\nplot(ret_mad$MU, type = \"l\")\n\n\n\n\n\n\n\nplot(ret_ham$MU/ret_mad$MU, type = \"l\")"
  },
  {
    "objectID": "case_study.html#case-study-2",
    "href": "case_study.html#case-study-2",
    "title": "Case studies",
    "section": "",
    "text": "Your second case study will once again be performed in pairs of Becky’s choosing! Each group will submit 1 report in the form of both a .Rmd (or .qmd) and a knitted/rendered PDF. These will be submitted to Canvas (not in-person) by Wednesday, 11/12 at 11:59pm.\nI anticipate you will run into questions/concerns – this is good. Don’t hesitate to come ask Becky!\nThe description of the case study and the data are found here:\n\nDescription\nData:  federalist_papers \nOptional .Rmd template:  caseStudy2 \n\n\n\n\nEach group will give a brief 5 minute presentation of their work to the class on 11/12. Presentation order will be randomized.\nYour presentation should be accompanied by a brief set of slides. As we are all aware of the data and the sampling model, these slides should focus mostly on your approach to answering the research question, as well as results (with interpretation).\n\nThink about embedding LaTex equations and R plots for your statistical model. These should be presented in an effective manner.\nYour presentation of results should answer the research question in an effective manner. Please include the required (at least one) visualization that answers the research question.\n\nYou should be prepared to answer questions from the audience. You should also be prepared to ask questions of presenters.\nYou don’t need to submit your slides for this case study! Just be prepared to present from a laptop!\nThis presentation is worth 5 points, in addition to the 40 points of the written portion. However, the presentation will be graded on an individual basis, rather than the entire group. A general rubric is:\n\n1 point: slides and presenter effectively share approach to answering the research question\n1 point: slides and presenter effectively share results that answer the research question(s)\n\nFor results tables/plots/CIs, etc: this includes describing what you’re showing (e.g. what exactly are you visualizing or calculating) and then interpreting and telling us the important things to take away from that item.\n\n1 point: speaker appears practiced and shares speaking time.\n\nBecause this presentation is short and you’re so close to your model, you shouldn’t be reading off any sort of notes!\n\n0.5 point: speaker is able to thoughtfully answer questions from audience\n1.5 points: asks at least one interesting/thoughtful/relevant question to other speakers, or gives at least one piece of useful and implementable feedback for improvement before submission of the written report\n\n“Effective” is a broad term that I use to cover:\n\nPresenting equations/distributions/slides in a logical order\nHaving font (both text and on figures/tables) be large enough for the audience to see\nSlides have enough text to be generally understood without a speaker, but each slide’s content is elevated/made complete by the speaker’s additions/commentary\nNo errors in terms of spelling, typesetting, and notation"
  },
  {
    "objectID": "case_study/case_study_2_template.html",
    "href": "case_study/case_study_2_template.html",
    "title": "STAT 412: Case Study 2",
    "section": "",
    "text": "DELETE ALL THE TEXT PROVIDED BY BECKY BEFORE SUBMITTING!\n# if you need packages, load them here\n\n# the following line of code sets the size of the figures when knitting for all code chunks. \n# You can also change the figure size in each specific chunk's header\nknitr::opts_chunk$set(fig.height = 3, fig.width = 5)\n\n# load your data here\n# Once you've set your file path, change the R chunk header to eval = TRUE\nmarriage &lt;- read_csv()"
  },
  {
    "objectID": "case_study/case_study_2_template.html#introduction",
    "href": "case_study/case_study_2_template.html#introduction",
    "title": "STAT 412: Case Study 2",
    "section": "Introduction",
    "text": "Introduction\nBriefly recap the research task at hand."
  },
  {
    "objectID": "case_study/case_study_2_template.html#model-description",
    "href": "case_study/case_study_2_template.html#model-description",
    "title": "STAT 412: Case Study 2",
    "section": "Model description",
    "text": "Model description\nClearly state your model (address questions 1 and 2). I encourage you to type up your model in math notation using Latex. For example:\n\\[Y_{1}, \\ldots, Y_{n} |\\theta \\overset{iid}{\\sim} f(y | \\theta)\\] ### Methods for answering research question\nClearly describe how you will use the model to address the research question. This includes providing some derivations or explanation for the reader (address question 3)."
  },
  {
    "objectID": "case_study/case_study_2_template.html#implementation",
    "href": "case_study/case_study_2_template.html#implementation",
    "title": "STAT 412: Case Study 2",
    "section": "Implementation",
    "text": "Implementation\nClearly state how you will implement your model (address question 4). You should provide enough detail such that someone else could implement your analysis."
  },
  {
    "objectID": "case_study/case_study_2_template.html#mcmc-code",
    "href": "case_study/case_study_2_template.html#mcmc-code",
    "title": "STAT 412: Case Study 2",
    "section": "MCMC code",
    "text": "MCMC code\n\n# DELETE BECKY's COMMENTS BEFORE SUBMITTING!\n\n\n# if you'd like to make a function, it looks like this:\nmy_function &lt;- function(x, y, n, ...){\n  # code you'd like to run in your function\n  a &lt;- sum(y)/n\n  b &lt;- sum(x)/n\n  \n  # this is a way to return multiple values from a function. The following code will return the a and b created above as objects called v1 and v2.\n  ret &lt;- list(v1 = a, v2 = b,...)\n  return(ret)\n}\n\n# then, if you'd like to call your function and access the returned value, you could do the following (delete before running your own code):\nmcmc1 &lt;- my_function(x = x1, y = y1, n = n1,...)\nv1_1 &lt;- mcmc1$v1\n\n\n# code for your MCMC should go here\n# remember to only keep display code necessary for submission!\n# I highly recommend making a your sampler into a function and putting it in the chunk above when you're ready\n\n\nDiagnostics"
  },
  {
    "objectID": "case_study/case_study_2_template.html#results",
    "href": "case_study/case_study_2_template.html#results",
    "title": "STAT 412: Case Study 2",
    "section": "Results",
    "text": "Results\n\nFindings\nProvide results with interpretation (address question 5). You should alternate between R code and text!"
  },
  {
    "objectID": "case_study/case_study_2_template.html#conclusion",
    "href": "case_study/case_study_2_template.html#conclusion",
    "title": "STAT 412: Case Study 2",
    "section": "Conclusion",
    "text": "Conclusion\nGive a conclusion that answers the research question and expands on the findings (address question 6)."
  }
]